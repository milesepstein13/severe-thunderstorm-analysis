{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_filter import *\n",
    "from utils_datetime import *\n",
    "from utils_geography import *\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from collections import Counter\n",
    "import math\n",
    "from shapely.vectorized import contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open and Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 'data'\n",
    "# outlooks, pph, reports = read_datasets(data_location)\n",
    "outlook1 = gp.read_file(f\"{data_location}/outlooks/all_outlooks_1.shp\", engine=\"pyogrio\")\n",
    "outlook2 = gp.read_file(f\"{data_location}/outlooks/all_outlooks_2.shp\", engine=\"pyogrio\")\n",
    "outlooks = gp.GeoDataFrame(pd.concat([outlook1, outlook2], ignore_index=True), crs=outlook1.crs)\n",
    "pph = xr.open_dataset(data_location + '/pph/all_pph.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_conversions = {'PST': timedelta(hours=8),\n",
    "                  'MST': timedelta(hours=7),\n",
    "                  'CST': timedelta(hours=6),\n",
    "                  'CSt': timedelta(hours=6),\n",
    "                  'CSC': timedelta(hours=6),\n",
    "                  'SCT': timedelta(hours=6),\n",
    "                  'EST': timedelta(hours=5),\n",
    "                  'ESt': timedelta(hours=5),\n",
    "                  'PDT': timedelta(hours=7),\n",
    "                  'MDT': timedelta(hours=6),\n",
    "                  'CDT': timedelta(hours=5),\n",
    "                  'EDT': timedelta(hours=4),\n",
    "                  'HST': timedelta(hours=10),\n",
    "                  'SST': timedelta(hours=11),\n",
    "                  'GST': timedelta(hours=10),\n",
    "                  'AKS': timedelta(hours=9),\n",
    "                  'AST': timedelta(hours=4),\n",
    "                  'UNK': timedelta(hours=5),\n",
    "                  'GMT': timedelta(0)}\n",
    "\n",
    "def get_reports_date_strings(date_times, timezones):\n",
    "    # returns list of strings of date of given datetime and timezone (where day cutoffs are 12-12 UTC) formatted as 'YYYYMMDD0000'\n",
    "    for datetime, timezone, i in zip(date_times, timezones, range(len(timezones))):\n",
    "        #print(datetime + ' ' + timezone[:3])\n",
    "        datetime = parser.parse(datetime)\n",
    "        datetime = datetime + tz_conversions[timezone[:3]]\n",
    "        #print(datetime)\n",
    "        if (datetime.hour < 12):\n",
    "            datetime = datetime - timedelta(days = 1)\n",
    "        if datetime.year > 2049:\n",
    "            datetime = datetime - relativedelta(years = 100)\n",
    "        datetime = datetime.strftime(\"%Y%m%d\") + '0000'\n",
    "        if i == 0:\n",
    "            ret = [datetime]\n",
    "        else:\n",
    "            ret.append(datetime)\n",
    "    return ret\n",
    "\n",
    "def get_pph_date_strings(times):\n",
    "    # returns a list of strings of given dates formatted as 'YYYYMMDD0000'\n",
    "    for datetime, i in zip(times, range(len(times))):\n",
    "        string = datetime.dt.strftime(\"%Y%m%d\").values + '0000'\n",
    "        if i == 0:\n",
    "            ret = [string]\n",
    "        else:\n",
    "            ret.append(string)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reports['DATE'] = get_reports_date_strings(reports['BEGIN_DATE_TIME'], reports['CZ_TIMEZONE']) \n",
    "pph['time'] = get_pph_date_strings(pph.time) \n",
    "# subset outlooks into only one day 1, two day 2, and one day 3 categorical outlooks \n",
    "# day 3: cycle not -1. day 2: cycle not -1. Day 1: cycle 6. Category: categorical. \n",
    "#outlooks = outlooks[(((outlooks['DAY'] == 1) & (outlooks['CYCLE'] == 6)) | ((outlooks['DAY'] == 2) & (outlooks['CYCLE'] != -1)) | ((outlooks['DAY'] == 3) & (outlooks['CYCLE'] != -1)))\n",
    "#        & (outlooks['CATEGORY'] == 'CATEGORICAL')]\n",
    "\n",
    "# reset incicies\n",
    "outlooks = outlooks.reset_index(drop=True)\n",
    "#reports = reports.drop(columns=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_outlook_dataset = xr.open_dataset('data/outlooks/grid_outlooks.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridize outlooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlooks_subset(outlooks, outlook_type):\n",
    "    outlooks = outlooks[(outlooks['THRESHOLD'] != 'SIGN') & (outlooks['THRESHOLD'] != 'TSTM')]\n",
    "    if outlook_type == 'Day 3':\n",
    "        return outlooks[(outlooks['DAY'] == 3) & (outlooks['CYCLE'] != -1) & (outlooks['CATEGORY'] == 'ANY SEVERE')]\n",
    "    elif outlook_type == 'Day 2 7':\n",
    "        return outlooks[(outlooks['DAY'] == 2) & (outlooks['CYCLE'] == 7) & (outlooks['CATEGORY'] == 'ANY SEVERE')]\n",
    "    elif outlook_type == 'Day 2 17':\n",
    "        return outlooks[(outlooks['DAY'] == 2) & (outlooks['CYCLE'] == 17) & (outlooks['CATEGORY'] == 'ANY SEVERE')]\n",
    "    elif outlook_type == 'Day 1':\n",
    "        return outlooks[(outlooks['DAY'] == 1) & (outlooks['CYCLE'] == 6) & (outlooks['CATEGORY'] == 'ANY SEVERE')]\n",
    "    elif outlook_type == 'Day 1 Wind':\n",
    "        return outlooks[(outlooks['DAY'] == 1) & (outlooks['CYCLE'] == 6) & (outlooks['CATEGORY'] == 'WIND')]\n",
    "    elif outlook_type == 'Day 1 Hail':\n",
    "        return outlooks[(outlooks['DAY'] == 1) & (outlooks['CYCLE'] == 6) & (outlooks['CATEGORY'] == 'HAIL')]\n",
    "    elif outlook_type == 'Day 1 Tornado':\n",
    "        return outlooks[(outlooks['DAY'] == 1) & (outlooks['CYCLE'] == 6) & (outlooks['CATEGORY'] == 'TORNADO')]\n",
    "    \n",
    "    elif outlook_type == 'Day 2 7 Wind':\n",
    "        return outlooks[(outlooks['DAY'] == 2) & (outlooks['CYCLE'] == 7) & (outlooks['CATEGORY'] == 'WIND')]\n",
    "    elif outlook_type == 'Day 2 17 Wind':\n",
    "        return outlooks[(outlooks['DAY'] == 2) & (outlooks['CYCLE'] == 17) & (outlooks['CATEGORY'] == 'WIND')]\n",
    "    elif outlook_type == 'Day 2 7 Hail':\n",
    "        return outlooks[(outlooks['DAY'] == 2) & (outlooks['CYCLE'] == 7) & (outlooks['CATEGORY'] == 'HAIL')]\n",
    "    elif outlook_type == 'Day 2 17 Hail':\n",
    "        return outlooks[(outlooks['DAY'] == 2) & (outlooks['CYCLE'] == 17) & (outlooks['CATEGORY'] == 'HAIL')]\n",
    "    elif outlook_type == 'Day 2 7 Tornado':\n",
    "        return outlooks[(outlooks['DAY'] == 2) & (outlooks['CYCLE'] == 7) & (outlooks['CATEGORY'] == 'TORNADO')]\n",
    "    elif outlook_type == 'Day 2 17 Tornado':\n",
    "        return outlooks[(outlooks['DAY'] == 2) & (outlooks['CYCLE'] == 17) & (outlooks['CATEGORY'] == 'TORNADO')]\n",
    "    \n",
    "    raise Exception(\"Invalid outlook_type given to get_outlooks_subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as in mca: create_gridded_outlook_dataset. But will need to work overall, not just by hazard. day 3 is overall probability, days 1 and 2 by hazard\n",
    "# day 3 use ANY SEVERE, day 2 use ANY SEVERE, day 1 construct from each hazard (assuming independence? or use highest prob, which basically assumes complete dependence? Is this what is done for day 2?)\n",
    "# Things are entirely categorical before 2002, so even more reason to make that the cutoff.\n",
    "\n",
    "outlook_types = ['Day 3', 'Day 2 7', 'Day 2 17', \n",
    "                 'Day 2 7 Wind', 'Day 2 7 Hail', 'Day 2 7 Tornado', \n",
    "                 'Day 2 17 Wind', 'Day 2 17 Hail', 'Day 2 17 Tornado',\n",
    "                 'Day 1 Wind', 'Day 1 Hail', 'Day 1 Tornado', \n",
    "                 'Day 1']\n",
    "\n",
    "outlook_dataset = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        lat=(['y', 'x'], pph['lat'].data),\n",
    "        lon=(['y', 'x'], pph['lon'].data)\n",
    "    ),\n",
    "    coords=dict(\n",
    "        time=(['time'], pph['time'].data),\n",
    "        x=(['x'], pph['x'].data),\n",
    "        y=(['y'], pph['y'].data),\n",
    "        outlook=(['outlook'], outlook_types)\n",
    "    ),\n",
    "    attrs=dict(description=\"outlook as a percentage as a function of date, lat/lon, and which hazard type\",\n",
    "            grid = pph.grid),\n",
    ")\n",
    "\n",
    "outlook_dataset = outlook_dataset.assign(prob = (('time', 'y', 'x', 'outlook'), np.full((len(outlook_dataset['time']), len(outlook_dataset['y']), len(outlook_dataset['x']), len(outlook_types)), 0.0)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding an additional year\n",
    "#outlook_dataset = old_outlook_dataset.reindex(time=pph['time'], fill_value=0)\n",
    "#del old_outlook_dataset\n",
    "#outlook_dataset\n",
    "# just full of zeros in new year, fill below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo_times = outlook_dataset['time']#[outlook_dataset['time'].str.startswith('2023')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = 'data/outlooks/grid_outlooks.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize_polygons(polygons, thresholds, lat_grid, lon_grid):\n",
    "    result = np.zeros(lat_grid.shape)\n",
    "    for poly, thresh in zip(polygons, thresholds):\n",
    "        mask = contains(poly, lon_grid, lat_grid)\n",
    "        result[mask & (result == 0)] = thresh  # only fill unassigned cells\n",
    "    return result\n",
    "\n",
    "# Extract static lat/lon once\n",
    "lat_grid = outlook_dataset.lat.values  # shape (y, x)\n",
    "lon_grid = outlook_dataset.lon.values\n",
    "\n",
    "# Loop over each outlook type\n",
    "for outlook_type in outlook_types:\n",
    "    print(outlook_type)\n",
    "    outlooks_subset = get_outlooks_subset(outlooks, outlook_type)\n",
    "    grouped_outlooks = dict(tuple(outlooks_subset.groupby('DATE')))\n",
    "\n",
    "    array = np.zeros((len(todo_times), lat_grid.shape[0], lat_grid.shape[1]))\n",
    "\n",
    "    oldyear = None\n",
    "    for i, date in enumerate(todo_times.values):\n",
    "        #year = date[:4]\n",
    "        #if year != oldyear:\n",
    "        #    print(year)\n",
    "        #    oldyear = year\n",
    "\n",
    "        outlooks_date = grouped_outlooks.get(date)\n",
    "        if outlooks_date is not None and len(outlooks_date) > 0:\n",
    "            outlooks_date = outlooks_date.sort_values(by='THRESHOLD', ascending=False)\n",
    "            polygons = outlooks_date['geometry'].tolist()\n",
    "            thresholds = outlooks_date['THRESHOLD'].tolist()\n",
    "\n",
    "            array[i] = rasterize_polygons(polygons, thresholds, lat_grid, lon_grid)\n",
    "\n",
    "    # Convert to DataArray and assign into dataset\n",
    "    me = xr.DataArray(array, coords={\n",
    "        'time': todo_times,\n",
    "        'y': outlook_dataset.y.values,\n",
    "        'x': outlook_dataset.x.values\n",
    "    }, dims=['time', 'y', 'x'])\n",
    "\n",
    "    outlook_dataset['prob'].loc[dict(outlook=outlook_type, time=todo_times)] = me\n",
    "\n",
    "    # Save after each outlook type (optional)\n",
    "    outlook_dataset.to_netcdf(save_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlook_dataset.to_netcdf('data/outlooks/grid_outlooks.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlook_dataset['prob'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlook_dataset = xr.open_dataset(save_location)\n",
    "outlook_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "outlook_dataset.sel(outlook = 'Day 1', time = '202304060000').prob.max(dim = ['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build day 1 and Feb 1 2020- day 2 probabilities: max (assuming total dependence) seems right, set to True\n",
    "dependent = True\n",
    "\n",
    "for outlook in ['Day 1', 'Day 2 7', 'Day 2 17']:\n",
    "    print(outlook)\n",
    "    year = ''\n",
    "    for time in outlook_dataset['time']:\n",
    "        time = str(time.values)\n",
    "        newyear = time[0:4]\n",
    "        if newyear != year:\n",
    "            print(newyear)\n",
    "            year = newyear\n",
    "        if dependent:\n",
    "            m = outlook_dataset['prob'].sel(time = time, outlook = [outlook + ' Wind', outlook + ' Hail', outlook + ' Tornado']).max(dim = 'outlook')\n",
    "            \n",
    "        else:\n",
    "            m = (1-(1-outlook_dataset['prob'].sel(time = time, outlook = [outlook + ' Wind'])).data * (1-outlook_dataset['prob'].sel(time = time, outlook = [outlook + ' Hail'])).data * (1-outlook_dataset['prob'].sel(time = time, outlook = [outlook + ' Tornado'])).data)[:, :, 0]\n",
    "        if m.values.max() > 0:\n",
    "            outlook_dataset['prob'].loc[dict(time = time, outlook = outlook)] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlook_dataset.to_netcdf('data/outlooks/grid_outlooks.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that max was a reasonable way to combine hazard probabilities\n",
    "plt.plot(np.convolve(outlook_dataset['prob'].sel(outlook = 'Day 1').max(dim=['x', 'y']).data[8489:], np.ones(365)/365, 'same'))\n",
    "plt.plot(np.convolve(outlook_dataset['prob'].sel(outlook = 'Day 2 17').max(dim=['x', 'y']).data[8489:], np.ones(365)/365, 'same'))\n",
    "plt.plot(np.convolve(outlook_dataset['prob'].sel(outlook = 'Day 2 7').max(dim=['x', 'y']).data[8489:], np.ones(365)/365, 'same'))\n",
    "plt.plot(np.convolve(outlook_dataset['prob'].sel(outlook = 'Day 3').max(dim=['x', 'y']).data[8489:], np.ones(365)/365, 'same'))\n",
    "plt.legend(['Day 1', 'Day 2 17z', 'Day 2 7z', 'Day 3'])\n",
    "if dependent:\n",
    "    plt.title('Daily Maximum Any-Hazard Probability Over Time')\n",
    "else:\n",
    "    plt.title('Daily Maximum Any-Hazard Probability Over Time (assuming independent hazards)')\n",
    "plt.ylabel('1-year Running Mean Daily Maximum Any-Hazard Probability')\n",
    "plt.xlabel('Days Since March 30, 2002')\n",
    "if dependent:\n",
    "    plt.savefig('plots/prob_over_time.png')\n",
    "else:\n",
    "    plt.savefig('plots/prob_over_time_indep.png')\n",
    "\n",
    "\n",
    "# This is kind of an interesting result on its own. Forecast practices have changed... higher risks issued less liberally"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
