{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_filter import *\n",
    "from utils_datetime import *\n",
    "from utils_geography import *\n",
    "from utils_plotting import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import metpy\n",
    "import numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading outlooks\n",
      "reading pph\n",
      "reading storm reports\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "data_location = 'data'\n",
    "outlooks, pph, reports = read_datasets(data_location, 'labelled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_date(outlooks, pph, reports):\n",
    "    earliest_date = max(min(outlooks['DATE']), min(pph['time']), min(reports['DATE'])) #TODO first two days of outlook dataset don't have day 3 forecast. but probably ok since not mdt\n",
    "    latest_date = min(max(outlooks['DATE']), max(pph['time']), max(reports['DATE']))\n",
    "    reports = reports[reports['DATE'] <= latest_date]\n",
    "    reports = reports[reports['DATE'] >= earliest_date]\n",
    "    outlooks = outlooks[outlooks['DATE'] <= latest_date]\n",
    "    outlooks = outlooks[outlooks['DATE'] >= earliest_date]\n",
    "    all_pph_dates = pph['time']\n",
    "    pph_dates = all_pph_dates[all_pph_dates <= latest_date]\n",
    "    pph_dates = pph_dates[pph_dates >= earliest_date]\n",
    "    pph = pph.sel(time = pph_dates)\n",
    "    return(outlooks, pph, reports)\n",
    "\n",
    "(outlooks, pph, reports) = consolidate_date(outlooks, pph, reports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['MAX_CAT', 'RAMP_CAT', 'SEASON', 'REGION', 'RAMP_UP', 'RAMP_DOWN', \n",
    "               'PPH_D_NUM',\n",
    "               'REPORT_NUM', 'TOR_NUM', 'WIND_NUM', 'HAIL_NUM', \n",
    "               'TOR_F', 'WINDSP_NUM', 'HAILSZ_NUM', \n",
    "               'BS_NUM', 'NEIGH_NUM', 'RMSE_NUM']\n",
    "\n",
    "category_dict = {\n",
    "    'NONE' : -1,\n",
    "    'TSTM': 0,\n",
    "    'MRGL': 1,\n",
    "    'SLGT': 2,\n",
    "    'ENH': 3,\n",
    "    'MDT': 4,\n",
    "    'HIGH': 5\n",
    "}\n",
    "\n",
    "ramp_dict = {\n",
    "    'up': 0,\n",
    "    'down': 1,\n",
    "    'both': 2,\n",
    "    'neither': 3\n",
    "}\n",
    "\n",
    "season_dict = {\n",
    "    'Winter': 0,\n",
    "    'Spring': 1,\n",
    "    'Summer': 2,\n",
    "    'Fall': 3\n",
    "}\n",
    "\n",
    "region_dict = {\n",
    "    'NONE': -1,\n",
    "    'West': 0,\n",
    "    'Great Plains': 1,\n",
    "    'Midwest': 2,\n",
    "    'Northeast': 3,\n",
    "    'South': 4\n",
    "}\n",
    "\n",
    "ramp_up_dict = {\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    '5': 5,\n",
    "    '6': 6\n",
    "}\n",
    "\n",
    "ramp_down_dict = {\n",
    "    '0': 0,\n",
    "    '-1': 1,\n",
    "    '-2': 2,\n",
    "    '-3': 3,\n",
    "    '-4': 4,\n",
    "    '-5': 5,\n",
    "    '-6': 6\n",
    "}\n",
    "\n",
    "pph_dict = {\n",
    "    'ZERO': 0,\n",
    "    'TSTM': 1,\n",
    "    'MRGL': 2,\n",
    "    'SLGT': 3,\n",
    "    'ENH': 4,\n",
    "    'MDT': 5,\n",
    "    'HIGH': 6\n",
    "}\n",
    "\n",
    "tor_dict = {\n",
    "    'NONE': -1,\n",
    "    'EFU': 0,\n",
    "    '(E)F0': 1,\n",
    "    '(E)F1': 2,\n",
    "    '(E)F2': 3,\n",
    "    '(E)F3': 4,\n",
    "    '(E)F4': 5,\n",
    "    '(E)F5': 6\n",
    "}\n",
    "\n",
    "dicts = [category_dict, ramp_dict, season_dict, region_dict, ramp_up_dict, ramp_down_dict, \n",
    "         None, \n",
    "         None, None, None, None, \n",
    "         tor_dict, None, None,\n",
    "         None, None, None] \n",
    "\n",
    "steps = [1, 1, 1, 1, 1, 1, \n",
    "         10, \n",
    "         100, 25, 100, 50, \n",
    "         1, 10, 1, \n",
    "         .0025, .001, .01]\n",
    "\n",
    "written_labels = ['Categorical Risk', 'Ramp', 'Season', 'Region', 'Ramp Up', 'Ramp Down', \n",
    "                  'Max PPH',\n",
    "                  'Total Storm Reports', 'Tornado Reports', 'Wind Reports', 'Hail Reports',\n",
    "                  'Max Tornado Rating', 'Max Wind Speed (kt)', 'Max Hail Size (in)',\n",
    "                  'Brier Score', 'Neighborhood Brier Score', 'RMSE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(pph, label_name, label_dict, written_label, titlestring, save_location, bins = 20, show=False):\n",
    "    if label_dict == None:\n",
    "        plt.hist(pph[label_name].values, bins = bins)\n",
    "    else:\n",
    "        labels = pph[label_name]\n",
    "        label_counts = labels.groupby(labels).count()\n",
    "        def sort_order(key):\n",
    "            return label_dict[str(key[0])]\n",
    "        sorted_labels, sorted_counts = zip(*sorted(zip(list(label_counts[label_name].values), label_counts.values), key = sort_order))\n",
    "        plt.bar(sorted_labels, sorted_counts)  \n",
    "    plt.xlabel(written_label)\n",
    "    plt.title('Number of ' + titlestring + ' Days With Each '  + written_label)\n",
    "    plt.ylabel(\"Number of Days\")\n",
    "    if save_location != None:\n",
    "        plt.savefig(save_location + '/' + written_label + '_distribution.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(pph, 'BS_NUM', None, 'Brier Score', '', None, show = True) # Seems to work, reverify once num_reports is fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_2d(pph, label_1, label_2, label_1_string, label_2_string, dict_1, dict_2, titlestring, save_location, show=False, defaultbins = 10, step_1 = 1, step_2 = 1):\n",
    "# plot 2d heatmap for any 2 labels\n",
    "\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "\n",
    "    for i in range(len(pph[label_1])):\n",
    "        if dict_1 != None:\n",
    "            data1.append(dict_1[str(pph[label_1].values[i])])\n",
    "        else: \n",
    "            data1.append(pph[label_1].values[i])\n",
    "        if dict_2 != None:\n",
    "            data2.append(dict_2[str(pph[label_2].values[i])])\n",
    "        else:\n",
    "            data2.append(pph[label_2].values[i])\n",
    "\n",
    "    \n",
    "    if dict_1 != None:\n",
    "        max1 = max(dict_1.values())\n",
    "        min1 = min(dict_1.values())\n",
    "        bins1 = np.linspace(min1-.5, max1+.5, 2+max1-min1)\n",
    "        irange = bins1.size-1\n",
    "    else:\n",
    "        if ((max(data1) - min(data1))/step_1).is_integer():\n",
    "            m = 2\n",
    "        else: \n",
    "            m = 1\n",
    "            \n",
    "        bins1 = np.insert(np.arange(step_1 * round(min(data1)/step_1), max(data1)+m*step_1, step_1), 0, 0)\n",
    "        \n",
    "        if isinstance(data1[1], numbers.Integral):\n",
    "            bins1[1] = bins1[1] + 1\n",
    "        else:\n",
    "            bins1[1] = bins1[1] + .00000000001\n",
    "        num_bins1 = len(bins1)-1\n",
    "        irange = num_bins1\n",
    "\n",
    "    if dict_2 != None:\n",
    "        max2 = max(dict_2.values())\n",
    "        min2 = min(dict_2.values())\n",
    "        bins2 = np.linspace(min2-.5, max2+.5, 2+max2-min2)\n",
    "        jrange = bins2.size-1\n",
    "    else:\n",
    "        if ((max(data2) - min(data2))/step_2).is_integer():\n",
    "            m = 2\n",
    "        else: \n",
    "            m = 1\n",
    "        bins2 = np.insert(np.arange(step_2 * round(min(data2)/step_2), max(data2)+m*step_2, step_2), 0, 0)\n",
    "        if isinstance(data2[1], numbers.Integral):\n",
    "            bins2[1] = bins2[1] + 1\n",
    "        else:\n",
    "            bins2[1] = bins2[1] + .00000000001\n",
    "        num_bins2 = len(bins2)-1\n",
    "        jrange = num_bins2\n",
    "\n",
    "    heatmap = np.histogram2d(data1, data2, bins = (bins1, bins2))\n",
    "    im = plt.imshow(heatmap[0],  norm=colors.LogNorm())\n",
    "    plt.colorbar(im)\n",
    "\n",
    "    for i in range(irange): \n",
    "        for j in range(jrange): \n",
    "            plt.annotate(str(int(heatmap[0][i][j])), xy=(j, i), \n",
    "                        ha='center', va='center', color='black') \n",
    "\n",
    "    if dict_1 != None:\n",
    "        plt.yticks(range(len(list(dict_1.values()))), labels=list(dict_1.keys()))\n",
    "    else:\n",
    "        labels = [s + '+' for s in heatmap[1][range(num_bins1)].astype(str)]\n",
    "        labels[0] = '0'\n",
    "        if isinstance(data1[1], numbers.Integral):\n",
    "            labels[1] = '1+'\n",
    "        else:\n",
    "            labels[1] = '0+'\n",
    "        plt.yticks(range(num_bins1), labels = labels) \n",
    "        plt.yticks(fontsize=8)\n",
    "    if dict_2 != None:\n",
    "        plt.xticks(range(len(list(dict_2.values()))), labels=list(dict_2.keys()))\n",
    "    else:\n",
    "        labels = [s + '+' for s in heatmap[2][range(num_bins2)].astype(str)]\n",
    "        labels[0] = '0'\n",
    "        if isinstance(data2[1], numbers.Integral):\n",
    "            labels[1] = '1+'\n",
    "        else:\n",
    "            labels[1] = '0+'\n",
    "        plt.xticks(range(num_bins2), labels = labels)\n",
    "        plt.xticks(fontsize=8)\n",
    "\n",
    "    plt.ylabel(label_1_string)\n",
    "    plt.xlabel(label_2_string)\n",
    "\n",
    "    plt.title(\"Number of \" + titlestring + \" Days with each Combination of \" + label_1_string + \" and \" +  label_2_string)\n",
    "    if save_location != None:\n",
    "        plt.savefig(save_location + '/' + label_1_string + '_' + label_2_string + '_distribution.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution_2d(pph, 'REPORT_NUM', 'NEIGH_NUM', 'Num Reports', 'Neighborhood BS', None, None, '', None, show = True, step_1 = 100, step_2 = .002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS NEEDED TO BE RERUN TWICE FOR SOME REASON\n",
    "\n",
    "# moderate and up days only:\n",
    "all_pph_dates = pph['time']\n",
    "mdt_pph_dates = all_pph_dates[pph['MAX_CAT'].isin(['MDT', 'HIGH'])]\n",
    "mdt_pph = pph.sel(time = mdt_pph_dates)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dates since new categorical system \n",
    "new_cutoff = '201410230000'\n",
    "new_pph_dates = all_pph_dates[all_pph_dates >= new_cutoff]\n",
    "new_pph = pph.sel(time = new_pph_dates)\n",
    "\n",
    "# Moderate dates in new system\n",
    "mdt_new_pph_dates = mdt_pph_dates[mdt_pph_dates >= new_cutoff]\n",
    "mdt_new_pph = pph.sel(time = mdt_new_pph_dates)\n",
    "\n",
    "\n",
    "# dates since day 3 added\n",
    "day3_cutoff = '200203300000'\n",
    "day3_pph_dates = all_pph_dates[all_pph_dates >= day3_cutoff]\n",
    "day3_pph = pph.sel(time = day3_pph_dates)\n",
    "\n",
    "# Moderate dates since day 3 added\n",
    "mdt_day3_pph_dates = mdt_pph_dates[mdt_pph_dates >= day3_cutoff]\n",
    "mdt_day3_pph = pph.sel(time = mdt_day3_pph_dates)\n",
    "\n",
    "\n",
    "# dates since early day 2 added\n",
    "day21_cutoff = '199707100000'\n",
    "day21_pph_dates = all_pph_dates[all_pph_dates >= day21_cutoff]\n",
    "day21_pph = pph.sel(time = day21_pph_dates)\n",
    "\n",
    "\n",
    "# Moderate dates since early day 2 added\n",
    "mdt_day21_pph_dates = mdt_pph_dates[mdt_pph_dates >= day21_cutoff]\n",
    "mdt_day21_pph = pph.sel(time = mdt_day21_pph_dates)\n",
    "\n",
    "\n",
    "# dates since late day 2 added\n",
    "day22_cutoff = '199504040000'\n",
    "day22_pph_dates = all_pph_dates[all_pph_dates >= day22_cutoff]\n",
    "day22_pph = pph.sel(time = day22_pph_dates)\n",
    "\n",
    "# Moderate since late day 2 added\n",
    "mdt_day22_pph_dates = mdt_pph_dates[mdt_pph_dates >= day22_cutoff]\n",
    "mdt_day22_pph = pph.sel(time = mdt_day22_pph_dates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(pph, label_names, dicts, written_labels, shortstring, titlestring, show=False):\n",
    "    \n",
    "    for i in range(len(written_labels)):\n",
    "        plot_distribution(pph, label_names[i], dicts[i], written_labels[i], titlestring, 'plots/label_distributions/'+ shortstring+'/1d/', show=show)\n",
    "\n",
    "    for i in range(len(label_names)):\n",
    "        for j in range(i):\n",
    "            plot_distribution_2d(pph, label_names[i], label_names[j], written_labels[i], written_labels[j], dicts[i], dicts[j], titlestring, 'plots/label_distributions/'+ shortstring+'/2d/', show=show, step_1 = steps[i], step_2 = steps[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(pph, label_names, dicts, written_labels, 'all', 'All')\n",
    "make_plots(mdt_pph, label_names, dicts, written_labels, 'mdt', 'Moderate')\n",
    "\n",
    "make_plots(new_pph, label_names, dicts, written_labels, 'new', 'New')\n",
    "make_plots(mdt_new_pph, label_names, dicts, written_labels, 'mdt_new', 'Moderate New')\n",
    "\n",
    "make_plots(day3_pph, label_names, dicts, written_labels, 'day3', 'Since 2002')\n",
    "make_plots(mdt_day3_pph, label_names, dicts, written_labels, 'mdt_day3', 'Moderate Since 2002')\n",
    "\n",
    "make_plots(day21_pph, label_names, dicts, written_labels, 'day21', 'Since 1997')\n",
    "make_plots(mdt_day21_pph, label_names, dicts, written_labels, 'mdt_day21', 'Moderate Since 1997')\n",
    "\n",
    "make_plots(day22_pph, label_names, dicts, written_labels, 'day22', 'Since 1995')\n",
    "make_plots(mdt_day22_pph, label_names, dicts, written_labels, 'mdt_day22', 'Moderate Since 1995')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD NON-GENERALIZED PLOTTING OF RAMPS / SCRATCH WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate: old ramp ups by 5? Why lots of 5 and not 4? And none region, make sure no PPH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = outlooks[outlooks['REGION'] != 'NONE']\n",
    "test[test['DATE'] <= '199203160000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outlooks = outlooks[outlooks['MAX_CAT'] == 'SLGT']\n",
    "test_outlooks = test_outlooks[test_outlooks['RAMP_UP'] == 3]\n",
    "set(test_outlooks['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlooks[outlooks['DATE'] == '200208030000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make function that plots all 3 outlooks, PPH, and reports for one day to spotcheck\n",
    "# with utils_plotting functions\n",
    "def plot_day(datestring, outlooks, pph, reports):\n",
    "    outlooks_day = outlooks[outlooks['DATE'] == datestring]\n",
    "    pph_day = pph.sel(time=datestring)\n",
    "    reports_day = reports[reports['DATE'] == datestring]\n",
    "    \n",
    "    print('plotting outlooks')\n",
    "    plot_outlooks_day(outlooks_day, 'plots/daily/'+datestring+'/outlooks', ['CATEGORICAL'], show=True)\n",
    "    print('plotting pph')\n",
    "    plot_pph_day(pph_day, 'plots/daily/'+datestring+'/pph', ['total'], show=True, sig = False)\n",
    "    #print('plotting reports')\n",
    "    #plot_reports(reports_day, 'plots/daily/'+datestring+'/reports', ['Hail', 'Thunderstorm Wind', 'Tornado'], show=True)\n",
    "    return\n",
    "\n",
    "#plot_day('200504220000', outlooks, pph, reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_day('201010100000', outlooks, pph, reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ramps(pph, title_insert=''):\n",
    "    # 2d histogram of ramps\n",
    "    # NOT FOR USE\n",
    "    ramp_up_bins = [-.5, .5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5]\n",
    "    ramp_up_amounts = [0, 1, 2, 3, 4, 5, 6]\n",
    "    ramp_down_amounts = [-6, -5, -4, -3, -2, -1, 0]\n",
    "    ramp_down_bins = [-6.5, -5.5, -4.5, -3.5, -2.5, -1.5, -.5, .5]\n",
    "    heatmap = np.histogram2d(np.array(pph['RAMP_UP'][pph['RAMP_UP']!= 'NONE'], dtype=int), np.array(pph['RAMP_DOWN'][pph['RAMP_UP']!= 'NONE'], dtype=int), bins = (ramp_up_bins, ramp_down_bins))\n",
    "    im = plt.imshow(heatmap[0],  norm=colors.LogNorm())\n",
    "    plt.colorbar(im)\n",
    "    bins = len(ramp_up_bins)\n",
    "    for i in range(bins-1): \n",
    "        for j in range(bins-1): \n",
    "            plt.annotate(str(int(heatmap[0][i][j])), xy=(j, i), \n",
    "                        ha='center', va='center', color='black') \n",
    "\n",
    "    plt.xticks(ramp_up_amounts, labels=ramp_down_amounts)\n",
    "    plt.yticks(ramp_up_amounts, labels=ramp_up_amounts)\n",
    "    plt.xlabel(\"Ramp Down\")\n",
    "    plt.ylabel(\"Ramp Up\")\n",
    "    plt.title(\"Number of \" + title_insert + \"Days with each Ramp Up and Ramp Down Amount\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(mdt_pph['time'].values).replace('\\n ', ' ').replace(' ', ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdt_new_pph['time'].where(mdt_new_pph['MAX_CAT'] == 'HIGH')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
