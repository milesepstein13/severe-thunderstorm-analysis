{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates Dataset where values are for the probabilistic contingency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import cartopy as cp\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from scipy.ndimage import map_coordinates\n",
    "import metpy.calc as mpcalc\n",
    "from geographiclib.geodesic import Geodesic\n",
    "from utils_datetime import *\n",
    "from utils_filter import *\n",
    "from geopy import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load grid pph and outlook\n",
    "pph = xr.open_dataset('data/pph/labelled_pph.nc')\n",
    "outlooks = xr.open_dataset('data/outlooks/grid_outlooks.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset in time, a/b/c/d, hazard\n",
    "hazard_types= ['Wind', 'Hail', 'Tornado', 'All Hazard']\n",
    "regions = ['West', 'Great Plains', 'Midwest', 'South', 'Northeast', 'CONUS']\n",
    "\n",
    "contingency_dataset = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        a=(['time', 'hazard', 'region'], np.full((len(pph['time']), len(hazard_types), len(regions)), 0.0)),\n",
    "        b=(['time', 'hazard', 'region'], np.full((len(pph['time']), len(hazard_types), len(regions)), 0.0)),\n",
    "        c=(['time', 'hazard', 'region'], np.full((len(pph['time']), len(hazard_types), len(regions)), 0.0)),\n",
    "        d=(['time', 'hazard', 'region'], np.full((len(pph['time']), len(hazard_types), len(regions)), 0.0))\n",
    "    ),\n",
    "    coords=dict(\n",
    "        time=(['time'], pph['time'].data),\n",
    "        hazard=(['hazard'], hazard_types),\n",
    "        region = (['region'], regions)\n",
    "    ),\n",
    "    attrs=dict(description=\"Number of a, b, c, and d in contingency tables for each day and hazard type, as calculated probabilistically from outlook and PPH probabilities\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pph_key_dict = {\n",
    "    'Wind': 'p_perfect_wind',\n",
    "    'Hail': 'p_perfect_hail',\n",
    "    'Tornado': 'p_perfect_tor',\n",
    "    'All Hazard': 'p_perfect_totalsvr'\n",
    "}\n",
    "\n",
    "outlook_key_dict = {\n",
    "    'Wind': 'Day 1 Wind',\n",
    "    'Hail': 'Day 1 Hail',\n",
    "    'Tornado': 'Day 1 Tornado',\n",
    "    'All Hazard': 'Day 1'\n",
    "}\n",
    "\n",
    "oldyear = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"severe_thunderstorm_miles_new1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating masks for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(lat, lon, geolocator):\n",
    "    location = geolocator.reverse(str(lat)+\",\"+str(lon))\n",
    "    if location == None:\n",
    "        return None\n",
    "    address = location.raw['address']\n",
    "    state = address.get('state', '')\n",
    "    return state\n",
    "\n",
    "regions_dict = { # list of states fully within each region (doesn't include AK, HI, CO, NM)\n",
    "        'West': ['Washington', 'Oregon', 'California', 'Idaho', 'Montana', 'Wyoming', 'Utah', 'Arizona'],\n",
    "        'Midwest': ['North Dakota', 'South Dakota', 'Minnesota', 'Iowa', 'Wisconsin', 'Illinois', 'Michigan', 'Indiana', 'Ohio', 'Kentucky'],\n",
    "        'Great Plains': ['Nebraska', 'Kansas', 'Oklahoma', 'Texas', 'Missouri'],\n",
    "        'Northeast': ['Maine', 'Vermont', 'New Hampshire', 'Massachusetts', 'Rhode Island', 'Connecticut', 'New York', 'Pennsylvania', 'New Jersey', 'Delaware', 'Maryland', 'District of Columbia', 'West Virginia'],\n",
    "        'South': ['Virginia', 'Arkansas', 'Louisiana', 'Tennessee', 'Mississippi', 'Alabama', 'Georgia', 'North Carolina', 'South Carolina', 'Florida']\n",
    "    }\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"severe_thunderstorm_miles53\")\n",
    "west_threshold_co_nm = -105\n",
    "\n",
    "def mask_function(lat, lon):\n",
    "\n",
    "    if lat > 49 or lat < 24 or lon < -125 or lon > -65:\n",
    "        return None\n",
    "    \n",
    "    elif lat < 31 and lon < -108:\n",
    "        return None\n",
    "    \n",
    "    elif lat < 32 and lon > -80:\n",
    "        return None\n",
    "    \n",
    "    elif lat > 35 and lat < 49 and lon > -121 and lon < -105:\n",
    "        return 'West'\n",
    "    \n",
    "    elif lat > 33 and lat < 41 and lon > -105 and lon < -95:\n",
    "        return 'Great Plains'\n",
    "    \n",
    "    elif lat > 31 and lat < 35 and lon > -83 and lon < -93:\n",
    "        return 'South'\n",
    "    \n",
    "\n",
    "\n",
    "    state = get_state(lat, lon, geolocator)\n",
    "    print(state)\n",
    "    if state == None:\n",
    "        return None\n",
    "    if state == 'Colorado' or state == 'New Mexico':\n",
    "        if lon < west_threshold_co_nm:\n",
    "            return 'West'\n",
    "        else:\n",
    "            return 'Great Plains'\n",
    "    for region in regions_dict:\n",
    "        if state in regions_dict[region]:\n",
    "            return region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty array for the mask\n",
    "mask = np.empty_like(pph['lat'].values, dtype=object)\n",
    "\n",
    "# Loop over each grid point\n",
    "for i in range(pph['lat'].shape[0]):  # Loop over the latitude dimension\n",
    "    for j in range(pph['lat'].shape[1]):  # Loop over the longitude dimension\n",
    "        lat = pph['lat'].values[i, j]\n",
    "        lon = pph['lon'].values[i, j]\n",
    "        print(lat, lon)\n",
    "        mask[i, j] = mask_function(lat, lon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isin(mask, ['West', 'South']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('conus_mask.npy', mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.where(mask == None, 'F', mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.load('conus_mask.npy', allow_pickle=True)\n",
    "\n",
    "unique_values = sorted(set(value for row in mask for value in row if value is not None))\n",
    "\n",
    "# Create a mapping for the strings and None\n",
    "value_to_int = {val: i for i, val in enumerate(unique_values)}\n",
    "value_to_int[None] = -1  # Assign -1 for None\n",
    "\n",
    "# Convert the 2D array to integers and ensure numerical dtype\n",
    "int_data = np.array([[value_to_int[val] for val in row] for row in mask[::-1]], dtype=int)\n",
    "plt.imshow(int_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in pph['time']:\n",
    "    year = str(time.values)[:4]\n",
    "    if year != oldyear:\n",
    "        oldyear = year\n",
    "        print(year)\n",
    "    for hazard in hazard_types:\n",
    "        for region in regions:\n",
    "            o = outlooks.sel(time = time, outlook = outlook_key_dict[hazard])['prob'].values\n",
    "            p = pph.sel(time = time)[pph_key_dict[hazard]].values/100\n",
    "\n",
    "            if region == 'CONUS':\n",
    "                o = o * np.isin(mask, [regions])\n",
    "                p = p * np.isin(mask, [regions])\n",
    "                o_ = (1-o) * np.isin(mask, [regions])\n",
    "                p_ = (1-p) * np.isin(mask, [regions])\n",
    "            else:\n",
    "                o = o * (mask == region)\n",
    "                p = p * (mask == region)\n",
    "                o_ = (1-o) * (mask == region)\n",
    "                p_ = (1-p) * (mask == region)\n",
    "\n",
    "            a = np.multiply(o, p).sum()\n",
    "            b = np.multiply(o, p_).sum()\n",
    "            c = np.multiply(o_, p).sum()\n",
    "            d = np.multiply(o_, p_).sum()\n",
    "\n",
    "            contingency_dataset['a'].loc[dict(time = time, hazard = hazard, region = region)] = a\n",
    "            contingency_dataset['b'].loc[dict(time = time, hazard = hazard, region = region)] = b\n",
    "            contingency_dataset['c'].loc[dict(time = time, hazard = hazard, region = region)] = c\n",
    "            contingency_dataset['d'].loc[dict(time = time, hazard = hazard, region = region)] = d\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that our dataset checks out\n",
    "old_dataset = xr.open_dataset('data/contingency/contingency_regions.nc')\n",
    "contingency_dataset.sel(region = 'CONUS')['c'].sum(), old_dataset['c'].sum(), contingency_dataset.sel(region = np.isin(contingency_dataset['region'], regions))['c'].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_dataset.to_netcdf('data/contingency/contingency_regions.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
