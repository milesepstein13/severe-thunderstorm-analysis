{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates Dataset where values are for the probabilistic contingency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import cartopy as cp\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from scipy.ndimage import map_coordinates\n",
    "import metpy.calc as mpcalc\n",
    "from geographiclib.geodesic import Geodesic\n",
    "from utils_datetime import *\n",
    "from utils_filter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load grid pph and outlook\n",
    "pph = xr.open_dataset('data/pph/labelled_pph.nc')\n",
    "outlooks = xr.open_dataset('data/outlooks/grid_outlooks.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset in time, a/b/c/d, hazard\n",
    "hazard_types= ['Wind', 'Hail', 'Tornado', 'All Hazard']\n",
    "contingency_dataset = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        a=(['time', 'hazard'], np.full((len(pph['time']), len(hazard_types)), 0.0)),\n",
    "        b=(['time', 'hazard'], np.full((len(pph['time']), len(hazard_types)), 0.0)),\n",
    "        c=(['time', 'hazard'], np.full((len(pph['time']), len(hazard_types)), 0.0)),\n",
    "        d=(['time', 'hazard'], np.full((len(pph['time']), len(hazard_types)), 0.0))\n",
    "    ),\n",
    "    coords=dict(\n",
    "        time=(['time'], pph['time'].data),\n",
    "        hazard=(['hazard'], hazard_types)\n",
    "    ),\n",
    "    attrs=dict(description=\"Number of a, b, c, and d in contingency tables for each day and hazard type, as calculated probabilistically from outlook and PPH probabilities\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pph_key_dict = {\n",
    "    'Wind': 'p_perfect_wind',\n",
    "    'Hail': 'p_perfect_hail',\n",
    "    'Tornado': 'p_perfect_tor',\n",
    "    'All Hazard': 'p_perfect_totalsvr'\n",
    "}\n",
    "\n",
    "outlook_key_dict = {\n",
    "    'Wind': 'Day 1 Wind',\n",
    "    'Hail': 'Day 1 Hail',\n",
    "    'Tornado': 'Day 1 Tornado',\n",
    "    'All Hazard': 'Day 1'\n",
    "}\n",
    "\n",
    "oldyear = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n"
     ]
    }
   ],
   "source": [
    "for time in pph['time']:\n",
    "    year = str(time.values)[:4]\n",
    "    if year != oldyear:\n",
    "        oldyear = year\n",
    "        print(year)\n",
    "    for hazard in hazard_types:\n",
    "        o = outlooks.sel(time = time, outlook = outlook_key_dict[hazard])['prob'].values\n",
    "        p = pph.sel(time = time)[pph_key_dict[hazard]].values/100\n",
    "\n",
    "        a = np.multiply(o, p).sum()\n",
    "        b = np.multiply(o, (1-p)).sum()\n",
    "        c = np.multiply((1-o), p).sum()\n",
    "        d = np.multiply((1-o), (1-p)).sum()\n",
    "\n",
    "        contingency_dataset['a'].loc[dict(time = time, hazard = hazard)] = a\n",
    "        contingency_dataset['b'].loc[dict(time = time, hazard = hazard)] = b\n",
    "        contingency_dataset['c'].loc[dict(time = time, hazard = hazard)] = c\n",
    "        contingency_dataset['d'].loc[dict(time = time, hazard = hazard)] = d\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_dataset.to_netcdf('data/contingency/contingency.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
