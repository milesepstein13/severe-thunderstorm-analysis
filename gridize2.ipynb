{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_filter import *\n",
    "from utils_datetime import *\n",
    "from utils_geography import *\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from collections import Counter\n",
    "import math\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 'data'\n",
    "outlooks, pph, reports = read_datasets(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_conversions = {'PST': timedelta(hours=8),\n",
    "                  'MST': timedelta(hours=7),\n",
    "                  'CST': timedelta(hours=6),\n",
    "                  'CSt': timedelta(hours=6),\n",
    "                  'CSC': timedelta(hours=6),\n",
    "                  'SCT': timedelta(hours=6),\n",
    "                  'EST': timedelta(hours=5),\n",
    "                  'ESt': timedelta(hours=5),\n",
    "                  'PDT': timedelta(hours=7),\n",
    "                  'MDT': timedelta(hours=6),\n",
    "                  'CDT': timedelta(hours=5),\n",
    "                  'EDT': timedelta(hours=4),\n",
    "                  'HST': timedelta(hours=10),\n",
    "                  'SST': timedelta(hours=11),\n",
    "                  'GST': timedelta(hours=10),\n",
    "                  'AKS': timedelta(hours=9),\n",
    "                  'AST': timedelta(hours=4),\n",
    "                  'UNK': timedelta(hours=5),\n",
    "                  'GMT': timedelta(0)}\n",
    "\n",
    "def get_reports_date_strings(date_times, timezones):\n",
    "    # returns list of strings of date of given datetime and timezone (where day cutoffs are 12-12 UTC) formatted as 'YYYYMMDD0000'\n",
    "    for datetime, timezone, i in zip(date_times, timezones, range(len(timezones))):\n",
    "        #print(datetime + ' ' + timezone[:3])\n",
    "        datetime = parser.parse(datetime)\n",
    "        datetime = datetime + tz_conversions[timezone[:3]]\n",
    "        #print(datetime)\n",
    "        if (datetime.hour < 12):\n",
    "            datetime = datetime - timedelta(days = 1)\n",
    "        if datetime.year > 2049:\n",
    "            datetime = datetime - relativedelta(years = 100)\n",
    "        datetime = datetime.strftime(\"%Y%m%d\") + '0000'\n",
    "        if i == 0:\n",
    "            ret = [datetime]\n",
    "        else:\n",
    "            ret.append(datetime)\n",
    "    return ret\n",
    "\n",
    "def get_pph_date_strings(times):\n",
    "    # returns a list of strings of given dates formatted as 'YYYYMMDD0000'\n",
    "    for datetime, i in zip(times, range(len(times))):\n",
    "        string = datetime.dt.strftime(\"%Y%m%d\").values + '0000'\n",
    "        if i == 0:\n",
    "            ret = [string]\n",
    "        else:\n",
    "            ret.append(string)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports['DATE'] = get_reports_date_strings(reports['BEGIN_DATE_TIME'], reports['CZ_TIMEZONE']) \n",
    "pph['time'] = get_pph_date_strings(pph.time) \n",
    "# subset outlooks into only one day 1, two day 2, and one day 3 categorical outlooks \n",
    "# day 3: cycle not -1. day 2: cycle not -1. Day 1: cycle 6. Category: categorical. # TODO: get prob by category \n",
    "#outlooks = outlooks[(((outlooks['DAY'] == 1) & (outlooks['CYCLE'] == 6)) | ((outlooks['DAY'] == 2) & (outlooks['CYCLE'] != -1)) | ((outlooks['DAY'] == 3) & (outlooks['CYCLE'] != -1)))\n",
    "#        & (outlooks['CATEGORY'] == 'CATEGORICAL')]\n",
    "\n",
    "# reset incicies\n",
    "outlooks = outlooks.reset_index(drop=True)\n",
    "reports = reports.drop(columns=['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridize reports -- will put into original gridize file after everything runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter reports to only be above severe thresholds\n",
    "\n",
    "reports.loc[reports['MAGNITUDE'] == '', 'MAGNITUDE'] = 0\n",
    "reports = reports[(reports['EVENT_TYPE'] == 'Tornado') | \n",
    "                  ((reports['EVENT_TYPE'] == 'Thunderstorm Wind') & (reports['MAGNITUDE'].astype(float) >= 50)) |\n",
    "                  ((reports['EVENT_TYPE'] == 'Hail') & (reports['MAGNITUDE'].astype(float) >= 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty reports dataset: same coords and time, 3 hazard dimensions (and total dimension and T/F dimension?)\n",
    "hazard_types= ['Wind', 'Hail', 'Tornado', 'Sig Wind', 'Sig Hail', 'Sig Tornado', 'Total Reports', 'Total Sig'] # TODO add true/false\n",
    "\n",
    "report_dataset = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        lat=(['y', 'x'], pph['lat'].data),\n",
    "        lon=(['y', 'x'], pph['lon'].data)\n",
    "    ),\n",
    "    coords=dict(\n",
    "        time=(['time'], pph['time'].data),\n",
    "        x=(['x'], pph['x'].data),\n",
    "        y=(['y'], pph['y'].data),\n",
    "        hazard=(['hazard'], hazard_types)\n",
    "    ),\n",
    "    attrs=dict(description=\"Number of each hazard type\",\n",
    "            grid = pph.grid),\n",
    ")\n",
    "\n",
    "report_dataset = report_dataset.assign(count = (('time', 'y', 'x', 'hazard'), np.full((len(report_dataset['time']), len(report_dataset['y']), len(report_dataset['x']), len(hazard_types)), 0)))\n",
    "report_dataset['count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nco.ncep.noaa.gov/pmb/docs/on388/tableb.html#GRID211 APPEARS TO SPECIFY\n",
    "resolution = 81270.5\n",
    "cent_lon = pph['lon'].sel(y=0, x=grid_shift).values\n",
    "grid_shift = 52\n",
    "cent_lat = pph['lat'].sel(y=0, x=grid_shift).values\n",
    "sp = (25, 25)\n",
    "data_crs = ccrs.LambertConformal(central_latitude = cent_lat, central_longitude=cent_lon, false_easting = 52*resolution, false_northing= 0, standard_parallels=sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through reports (filtered to only be severe as in labelling), adding 1 to appropriate count \n",
    "#               (nearest point? or within 25 mi? would leave out reports in \"gap\" between 4 25 mi circles. probably within 25 mi for technically correct definition. But can do nearest point and then check within 25 mi.)\n",
    "\n",
    "for i, row in reports.iterrows(): # for each report\n",
    "    date = row['DATE']\n",
    "    if i % 100000 == 0:\n",
    "        print('Row ' + str(i))\n",
    "    \n",
    "    if (date >= report_dataset['time'][0]) and (date <= report_dataset['time'][-1]): # reports in time frame of interest\n",
    "        # get grid points (x and y) of report location\n",
    "        if row['BEGIN_LON'] != '' and row['BEGIN_LAT'] != '':\n",
    "            x, y = data_crs.transform_point(float(row['BEGIN_LON']), float(row['BEGIN_LAT']), src_crs=ccrs.PlateCarree())\n",
    "            if not (math.isnan(x) or math.isnan(y)):\n",
    "                x, y = (x/resolution, y/resolution)\n",
    "                xgrid = round(x)\n",
    "                ygrid = round(y)\n",
    "\n",
    "                # check if report is within 25 mi of nearest gridpoint\n",
    "                if np.sqrt((xgrid-x)**2 + (ygrid-y)**2) < .5 and xgrid >= 0 and xgrid <= 92 and ygrid >= 0 and ygrid <= 64: # half a grid point away is 25 miles\n",
    "\n",
    "                    if row['EVENT_TYPE'] == 'Thunderstorm Wind':\n",
    "                        report_dataset['count'].loc[dict(time = date, x = xgrid, y = ygrid, hazard = 'Wind')] += 1\n",
    "                        if float(row['MAGNITUDE']) >= 65:\n",
    "                            report_dataset['count'].loc[dict(time = date, x = xgrid, y = ygrid, hazard = 'Sig Wind')] += 1\n",
    "\n",
    "                    elif row['EVENT_TYPE'] == 'Hail':\n",
    "                        report_dataset['count'].loc[dict(time = date, x = xgrid, y = ygrid, hazard = 'Hail')] += 1\n",
    "                        if float(row['MAGNITUDE']) >= 2:\n",
    "                            report_dataset['count'].loc[dict(time = date, x = xgrid, y = ygrid, hazard = 'Sig Hail')] += 1\n",
    "\n",
    "                    elif row['EVENT_TYPE'] == 'Tornado':\n",
    "                        report_dataset['count'].loc[dict(time = date, x = xgrid, y = ygrid, hazard = 'Tornado')] += 1\n",
    "                        rating_str = row['TOR_F_SCALE']\n",
    "                        if rating_str != 'EFU' and rating_str != '':\n",
    "                            if int(rating_str[-1]) >= 2:\n",
    "                                report_dataset['count'].loc[dict(time = date, x = xgrid, y = ygrid, hazard = 'Sig Tornado')] += 1\n",
    "\n",
    "                    else:\n",
    "                        raise Exception('Unexpected event type')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total counts and T/F\n",
    "report_dataset['count'].loc[dict(hazard = 'Total Reports')] = report_dataset['count'].sel(hazard = 'Wind') + report_dataset['count'].sel(hazard = 'Hail') + report_dataset['count'].sel(hazard = 'Tornado')\n",
    "report_dataset['count'].loc[dict(hazard = 'Total Sig')] = report_dataset['count'].sel(hazard = 'Sig Wind') + report_dataset['count'].sel(hazard = 'Sig Hail') + report_dataset['count'].sel(hazard = 'Sig Tornado')\n",
    "report_dataset = report_dataset.assign(bool = (('time', 'y', 'x', 'hazard'), (report_dataset['count'] > 0).data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = 'data/storm_reports/grid_reports.nc'\n",
    "report_dataset.to_netcdf(save_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messing around with projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cmr.earthdata.nasa.gov/search/concepts/C1214586272-SCIOPS.html\n",
    "# https://www.nco.ncep.noaa.gov/pmb/docs/on388/tableb.html#GRID211 APPEARS TO SPECIFY\n",
    "resolution = 81400\n",
    "grid_shift = 52\n",
    "cent_lon = pph['lon'].sel(y=0, x=grid_shift).values\n",
    "cent_lat = pph['lat'].sel(y=0, x=grid_shift).values\n",
    "sp = (25, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = 0\n",
    "testy = 0\n",
    "\n",
    "arrx = np.zeros_like(pph['lat'])\n",
    "arry = np.zeros_like(pph['lat'])\n",
    "\n",
    "data_crs = ccrs.LambertConformal(central_latitude = cent_lat, central_longitude=cent_lon, false_easting = 52*resolution, false_northing= 0, standard_parallels=sp)\n",
    "\n",
    "for testx in range(93):\n",
    "    for testy in range(65):\n",
    "        x, y = data_crs.transform_point(pph['lon'].sel(x = testx, y = testy).values, \n",
    "                                        pph['lat'].sel(x = testx, y = testy).values, \n",
    "                                        src_crs=ccrs.PlateCarree())\n",
    "        x, y = (x/resolution, y/resolution)\n",
    "        arrx[testy, testx] = x - testx\n",
    "        arry[testy, testx] = y - testy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imshow(arrx)\n",
    "plt.colorbar(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
