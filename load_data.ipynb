{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting familiar with all CO and PPH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import shapely as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as cx\n",
    "import cartopy as cp\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from utils_filter import *\n",
    "from utils_datetime import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = '~/Downloads'\n",
    "outlook_raw_location = raw_dir + '/outlooks'\n",
    "report_raw_location = raw_dir + '/storm_reports'\n",
    "pph_raw_location = raw_dir + '/pph'\n",
    "outlook_save_location = 'data/outlooks'\n",
    "report_save_location = 'data/storm_reports'\n",
    "pph_save_location = 'data/pph'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Convective outlooks and filter moderate days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read convective outlooks into outlooks\n",
    "year_list = [[1987, 1991], [1992, 1999], [2000, 2007], [2008, 2015], [2016, 2023]]\n",
    "for years, i in zip(year_list, range(len(year_list))):\n",
    "    print('reading file ' + str(i) + ', years ' + str(years[0]) +'-' + str(years[1]))\n",
    "    if i == 0:\n",
    "        outlooks_original = gp.read_file(outlook_raw_location + '/outlooks_' + str(years[0]) + '01010000_' + str(years[1]) + '12312359')\n",
    "    else:\n",
    "        outlooks_original = outlooks_original.append(gp.read_file(outlook_raw_location + '/outlooks_' + str(years[0]) + '01010000_' + str(years[1]) + '12312359'))\n",
    "print('files read')\n",
    "    \n",
    "outlooks_original\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dates datetime\n",
    "outlooks = outlooks_original\n",
    "outlooks['ISSUE'] = parse_datetime(outlooks['ISSUE'])\n",
    "outlooks['EXPIRE'] = parse_datetime(outlooks['EXPIRE'])\n",
    "outlooks['PRODISS'] = parse_datetime(outlooks['PRODISS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset incicies\n",
    "outlooks = outlooks.reset_index(drop=True)\n",
    "outlooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlooks = fix_month_issue(outlooks)    \n",
    "outlooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column with just valid date\n",
    "outlooks['DATE'] = create_dates(outlooks['EXPIRE'], -1)\n",
    "\n",
    "# identify dates with MDT\n",
    "mod_dates = identify_dates_above_threshold(outlooks, 'MDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of MDT days by year\n",
    "years_of_mdt = get_years(mod_dates)\n",
    "plt.hist(years_of_mdt, bins=range(min(years_of_mdt), max(years_of_mdt) + 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe containing only outlooks for days in which there was a MDT risk\n",
    "mdt_outlooks = outlooks[outlooks['DATE'].isin(mod_dates)]\n",
    "\n",
    "# convert datetimes back to strings\n",
    "outlooks = revert_all_datetimes(outlooks)\n",
    "mdt_outlooks = revert_all_datetimes(mdt_outlooks)\n",
    "\n",
    "# save dataframes\n",
    "outlooks.iloc[:int(len(outlooks)/2)].to_file(outlook_save_location + '/all_outlooks_1.shp')\n",
    "outlooks.iloc[int(len(outlooks)/2)+1:].to_file(outlook_save_location + '/all_outlooks_2.shp')\n",
    "mdt_outlooks.to_file(outlook_save_location + '/mdt_outlooks.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now read, combine, filter (to mdt), and save PPH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_types = ['wind', 'sig_wind', 'hail', 'sig_hail', 'tor', 'sig_tor']\n",
    "for hazard, i in zip(hazard_types, range(len(hazard_types))):\n",
    "    print('reading in ' + hazard + ' pph')\n",
    "    if i == 0:\n",
    "        pph_data = xr.open_dataset(pph_raw_location + '/pper_' + hazard + '_1979_2022.nc')\n",
    "    else:\n",
    "        new_data = xr.open_dataset(pph_raw_location + '/pper_' + hazard + '_1979_2022.nc')\n",
    "        pph_data = xr.merge([pph_data, new_data])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select pph data on days with mdt risk\n",
    "pph_data_mod = pph_data.sel(time=pph_data.time.dt.date.isin(mod_dates.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save full and moderate pph datasets\n",
    "pph_data.to_netcdf(pph_save_location + '/all_pph.nc')\n",
    "pph_data_mod.to_netcdf(pph_save_location + '/mdt_pph.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in, combine, filter, and save raw storm reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =['STATE', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_NAME', 'CZ_NAME', 'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT', 'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE', 'MAGNITUDE', 'MAGNITUDE_TYPE', 'TOR_F_SCALE', 'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE', 'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE', 'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH', 'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON']\n",
    "event_types = ['Funnel Cloud', 'Hail', 'Marine Hail', 'Marine Thunderstorm Wind', 'Thunderstorm Wind', 'Tornado', 'Waterspout']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in reports and combine into all_reports\n",
    "first = True\n",
    "for file in os.listdir(os.fsencode(report_raw_location)):\n",
    "    filename = os.fsdecode(file)\n",
    "    if 'StormEvents_details-ftp_v1.0_d' in filename:\n",
    "        print('reading' + filename)\n",
    "        reports = gp.read_file(report_raw_location + '/' + filename)\n",
    "        if first:\n",
    "            all_reports = filter_reports(reports, columns, event_types)\n",
    "            first = False\n",
    "        else:\n",
    "            all_reports = all_reports.append(filter_reports(reports, columns, event_types))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter all_reports to get all_reports_mdt\n",
    "all_reports['DATE'] = parse_datetime_reports(all_reports['BEGIN_DATE_TIME'])\n",
    "all_reports_mdt = all_reports[all_reports['DATE'].isin(mod_dates.tolist())]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save report data\n",
    "all_reports.to_csv(report_save_location + '/all_reports.csv')\n",
    "all_reports_mdt.to_csv(report_save_location + '/mdt_reports.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
