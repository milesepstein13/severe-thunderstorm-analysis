{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_filter import *\n",
    "from utils_datetime import *\n",
    "from utils_geography import *\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import math\n",
    "\n",
    "\n",
    "# TODO: 201804020000's day 3 forecasts are issued on 04/30--in reality, these forecasts were probably meant for 05/02. todo is clean for this sort of thing. Potentially in cleaning file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsets outlooks, pph, and report data in various ways (add label to each datapoint for each method of subsetting so can be pulled out of full dataset later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading outlooks 1\n",
      "reading outlooks 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miles\\OneDrive\\Documents\\UW\\Research\\utils_filter.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outlooks = outlooks.append(gp.read_file(data_location + '/outlooks/' + mod_string + '_outlooks_2.shp'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading pph\n",
      "reading storm reports\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "data_location = 'data'\n",
    "moderate = False # only consider moderate days\n",
    "labelled = False # start with already labelled data\n",
    "outlooks, pph, reports = read_datasets(data_location, moderate, labelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_conversions = {'PST': timedelta(hours=8),\n",
    "                  'MST': timedelta(hours=7),\n",
    "                  'CST': timedelta(hours=6),\n",
    "                  'CSt': timedelta(hours=6),\n",
    "                  'CSC': timedelta(hours=6),\n",
    "                  'SCT': timedelta(hours=6),\n",
    "                  'EST': timedelta(hours=5),\n",
    "                  'ESt': timedelta(hours=5),\n",
    "                  'PDT': timedelta(hours=7),\n",
    "                  'MDT': timedelta(hours=6),\n",
    "                  'CDT': timedelta(hours=5),\n",
    "                  'EDT': timedelta(hours=4),\n",
    "                  'HST': timedelta(hours=10),\n",
    "                  'SST': timedelta(hours=11),\n",
    "                  'GST': timedelta(hours=10),\n",
    "                  'AKS': timedelta(hours=9),\n",
    "                  'AST': timedelta(hours=4),\n",
    "                  'UNK': timedelta(hours=5),\n",
    "                  'GMT': timedelta(0)}\n",
    "\n",
    "def get_reports_date_strings(date_times, timezones):\n",
    "    # returns list of strings of date of given datetime and timezone (where day cutoffs are 12-12 UTC) formatted as 'YYYYMMDD0000'\n",
    "    for datetime, timezone, i in zip(date_times, timezones, range(len(timezones))):\n",
    "        #print(datetime + ' ' + timezone[:3])\n",
    "        datetime = parser.parse(datetime)\n",
    "        datetime = datetime + tz_conversions[timezone[:3]]\n",
    "        #print(datetime)\n",
    "        if (datetime.hour < 12):\n",
    "            datetime = datetime - timedelta(days = 1)\n",
    "        if datetime.year > 2049:\n",
    "            datetime = datetime - relativedelta(years = 100)\n",
    "        datetime = datetime.strftime(\"%Y%m%d\") + '0000'\n",
    "        if i == 0:\n",
    "            ret = [datetime]\n",
    "        else:\n",
    "            ret.append(datetime)\n",
    "    return ret\n",
    "\n",
    "def get_pph_date_strings(times):\n",
    "    # returns a list of strings of given dates formatted as 'YYYYMMDD0000'\n",
    "    for datetime, i in zip(times, range(len(times))):\n",
    "        string = datetime.dt.strftime(\"%Y%m%d\").values + '0000'\n",
    "        if i == 0:\n",
    "            ret = [string]\n",
    "        else:\n",
    "            ret.append(string)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dates to reports and pph in same format as in outlooks\n",
    "if labelled == False:\n",
    "    reports['DATE'] = get_reports_date_strings(reports['BEGIN_DATE_TIME'], reports['CZ_TIMEZONE']) \n",
    "    pph['time'] = get_pph_date_strings(pph.time) \n",
    "    # subset outlooks into only one day 1, two day 2, and one day 3 categorical outlooks \n",
    "    # day 3: cycle not -1. day 2: cycle not -1. Day 1: cycle 6. Category: categorical or none.\n",
    "    outlooks = outlooks[(((outlooks['DAY'] == 1) & (outlooks['CYCLE'] == 6)) | ((outlooks['DAY'] == 2) & (outlooks['CYCLE'] != -1)) | ((outlooks['DAY'] == 3) & (outlooks['CYCLE'] != -1)))\n",
    "            & (outlooks['CATEGORY'] != 'WIND') & (outlooks['CATEGORY'] != 'HAIL') & (outlooks['CATEGORY'] != 'TORNADO')& (outlooks['CATEGORY'] != 'ANY SEVERE')& (outlooks['CATEGORY'] != 'PROB')]\n",
    "\n",
    "    # reset incicies\n",
    "    outlooks = outlooks.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_outlooks_label(outlooks, label_dates, labels, label_name, none_label):\n",
    "    # adds new column with values from labels on the corresponding list of dates in label_dates (DONE)\n",
    "    print(\"adding a new column in outlooks\")\n",
    "    outlooks[label_name] = none_label\n",
    "    for label, dates in zip(labels, label_dates):\n",
    "        #print(label)\n",
    "        outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n",
    "    return outlooks\n",
    "\n",
    "def add_pph_label(pph, label_dates, labels, label_name, none_label):\n",
    "    # adds new variable with values from labels on the corresponding list of dates in label_dates (DONE)\n",
    "    print(\"adding new variable in pph\")\n",
    "    pph[label_name] = (('time'), np.full(len(pph['time']), none_label))\n",
    "    for label, dates in zip(labels, label_dates):\n",
    "        #print(label) # TODO: may only be adding first 4 letters of label\n",
    "        pph[label_name].loc[pph['time'].isin(dates)] = label  \n",
    "    return pph\n",
    "\n",
    "def add_reports_label(reports, label_dates, labels, label_name, none_label):\n",
    "    # adds new column with values from labels on the corresponding list of dates in label_dates (DONE)\n",
    "    reports[label_name] = none_label\n",
    "    print(\"adding a new column in reports\")\n",
    "    for label, dates in zip(labels, label_dates):\n",
    "       #print(label)\n",
    "       reports[label_name].loc[reports['DATE'].isin(dates)] = label #\n",
    "    return reports\n",
    "\n",
    "def add_labels(outlooks, pph, reports, label_dates, labels, label_name, none_label):\n",
    "    # adds labels, overwriting with later ones if a date has multiple labels\n",
    "    return(add_outlooks_label(outlooks, label_dates, labels, label_name, none_label), \n",
    "           add_pph_label(pph, label_dates, labels, label_name, none_label),\n",
    "           add_reports_label(reports, label_dates, labels, label_name, none_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_outlooks = outlooks\n",
    "new_pph = pph\n",
    "new_reports = reports.drop(columns=['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALWAYS RUN THROUGH HERE. THEN TO ADD MORE LABELS, RUN JUST THE LABELLING YOU WISH TO BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_1248\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in reports\n"
     ]
    }
   ],
   "source": [
    "# add max threshold forecasted for valid day to each datapoint\n",
    "\n",
    "categories = ['TSTM', 'MRGL', 'SLGT', 'ENH', 'MDT', 'HIGH']\n",
    "category_dates = []\n",
    "for category in categories:\n",
    "    category_dates.append(identify_dates_above_threshold(new_outlooks, category))\n",
    "\n",
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, category_dates, categories, 'MAX_CAT', 'NONE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by ramp up/down amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put new_outlooks in correct order\n",
    "\n",
    "new_outlooks['DATE_ORDER'] = 0\n",
    "for index, row in new_outlooks.iterrows():\n",
    "    if row['DAY'] == 3:\n",
    "        new_outlooks.at[index, 'DATE_ORDER'] = row['DATE'] + '1'\n",
    "    elif row['DAY'] == 1:\n",
    "        new_outlooks.at[index, 'DATE_ORDER'] = row['DATE'] + '4'\n",
    "    elif row['CYCLE'] == 7:\n",
    "        new_outlooks.at[index, 'DATE_ORDER'] = row['DATE'] + '2'\n",
    "    else:\n",
    "        new_outlooks.at[index, 'DATE_ORDER'] = row['DATE'] + '3'\n",
    "new_outlooks = new_outlooks.sort_values('DATE_ORDER')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and add ramp category for each datapoint. Potentially add 2 binary ramp up and ramp down (4 options are [up, down, up and down, niether]). How many forecasts to consider for each day? The day 3, both day 2, and the first day 1 (so 4 forecasts ramp)\n",
    "# dictionary of category to number\n",
    "category_dict = {\n",
    "    None : -1,\n",
    "    'NONE' : -1,\n",
    "    'TSTM': 0,\n",
    "    'MRGL': 1,\n",
    "    'SLGT': 2,\n",
    "    'ENH': 3,\n",
    "    'MDT': 4,\n",
    "    'HIGH': 5\n",
    "}\n",
    "\n",
    "(ramp_ups, ramp_downs, ramp_categories) = create_ramp_lists(new_outlooks, category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n",
      "adding a new column in reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_1248\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n",
      "adding a new column in reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_1248\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n",
      "adding a new column in reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_1248\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n"
     ]
    }
   ],
   "source": [
    "# TODO: make defaults be no ramping! NEXT!!\n",
    "# ramp up\n",
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, list(ramp_ups.values()), ramp_ups.keys(), 'RAMP_UP', 'NONE')\n",
    "\n",
    "# ramp down\n",
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, list(ramp_downs.values()), ramp_downs.keys(), 'RAMP_DOWN', 'NONE')\n",
    "\n",
    "# ramp categories\n",
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, list(ramp_categories.values()), ramp_categories.keys(), 'RAMP_CATEGORIES', 'NONE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by accurate/inaccurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider forecast issue time for day 1--subset reports (and revise pph?)--look at other studies to see how they handled multiple day 1 outlooks (see the one in slack). Starting point should be use first forecasts, later ones would be a different analysis for another time. Decide if we should denote these somehow.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n",
      "adding a new column in reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_1248\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n"
     ]
    }
   ],
   "source": [
    "# add column denoting season (4 met seasons as starting point)\n",
    "\n",
    "seasons = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "season_dates = get_season_dates(new_outlooks, seasons) # TODO: fix so it uses pph so it doesn't skip days NEXT!!\n",
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, season_dates, seasons, 'SEASON', 'NONE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide how to do... lower priotity, could do by state of center of highest category (or center of PPH?) Could start with super basic version\n",
    "# same regions as Anderson-Frey 2016\n",
    "# center is grid square with highest p_perfect prob of at least one hazard (assuming each hazard in independent)\n",
    "\n",
    "# TODO: some reports right near border turn into none bc nearest grid point is outside US. Add code to handle. NEXT!!\n",
    "\n",
    "# practically perfect probability of at least one hazard occuring near datapoint\n",
    "new_pph['p_perfect_total'] = (1 - (1-new_pph['p_perfect_wind']/100)*(1-new_pph['p_perfect_hail']/100)*(1-new_pph['p_perfect_tor']/100))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect regions in chunks (since doing it all at once can time out)\n",
    "regions = {\n",
    "        'West': [],\n",
    "        'Midwest': [],\n",
    "        'Great Plains': [],\n",
    "        'Northeast': [],\n",
    "        'South': [],\n",
    "        'NONE': []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = 10\n",
    "time_array = new_pph['time']\n",
    "chunk_size = math.ceil(len(time_array)/chunks)\n",
    "time_arrays = [time_array[i:i + chunk_size] for i in range(0, len(time_array), chunk_size)]\n",
    "for i in range(0, chunks):\n",
    "    chunk_regions = create_regions(new_pph.sel(time = time_arrays[i]))\n",
    "    for region in regions:\n",
    "        regions[region] += chunk_regions[region]\n",
    "    print('Added chunk ' + str(i) + ' to regions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, list(regions.values()), regions.keys(), 'REGION', 'NONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by environmental data (to do later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONCE YOU ADD THE LABELS YOU WANT, SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resave labelled data\n",
    "outlook_save_location = 'data/outlooks'\n",
    "pph_save_location = 'data/pph'\n",
    "report_save_location = 'data/storm_reports'\n",
    "\n",
    "new_outlooks.to_file(outlook_save_location + '/labelled_outlooks.shp')\n",
    "new_pph.to_netcdf(pph_save_location + '/labelled_pph.nc') # This file saved weirdly, but seems to be ok on rerun.\n",
    "new_reports.to_csv(report_save_location + '/labelled_reports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISSUE</th>\n",
       "      <th>EXPIRE</th>\n",
       "      <th>PRODISS</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>DAY</th>\n",
       "      <th>THRESHOLD</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>CYCLE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>geometry</th>\n",
       "      <th>MAX_CAT</th>\n",
       "      <th>DATE_ORDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198701091200</td>\n",
       "      <td>198701101200</td>\n",
       "      <td>198701080719</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>198701090000</td>\n",
       "      <td>None</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1987010900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198701091200</td>\n",
       "      <td>198701101200</td>\n",
       "      <td>198701081731</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>198701090000</td>\n",
       "      <td>None</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1987010900003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198701161200</td>\n",
       "      <td>198701171200</td>\n",
       "      <td>198701160615</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>6</td>\n",
       "      <td>198701160000</td>\n",
       "      <td>POLYGON ((-81.10300 30.60200, -81.08700 30.521...</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>1987011600004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198701191200</td>\n",
       "      <td>198701201200</td>\n",
       "      <td>198701180703</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>198701190000</td>\n",
       "      <td>None</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1987011900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198701221200</td>\n",
       "      <td>198701231200</td>\n",
       "      <td>198701210800</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>198701220000</td>\n",
       "      <td>None</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1987012200002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73061</th>\n",
       "      <td>202312311200</td>\n",
       "      <td>202401011200</td>\n",
       "      <td>202312301607</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>202312310000</td>\n",
       "      <td>None</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>2023123100003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73062</th>\n",
       "      <td>202312311200</td>\n",
       "      <td>202401011200</td>\n",
       "      <td>202312310520</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>202312310000</td>\n",
       "      <td>None</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>2023123100004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73063</th>\n",
       "      <td>202401011200</td>\n",
       "      <td>202401021200</td>\n",
       "      <td>202312310600</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>202401010000</td>\n",
       "      <td>None</td>\n",
       "      <td>NONE</td>\n",
       "      <td>2024010100002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73064</th>\n",
       "      <td>202401021200</td>\n",
       "      <td>202401031200</td>\n",
       "      <td>202312310815</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>8</td>\n",
       "      <td>202401020000</td>\n",
       "      <td>POLYGON ((-90.74500 28.71100, -91.08300 28.732...</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>2024010200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73065</th>\n",
       "      <td>202401011200</td>\n",
       "      <td>202401021200</td>\n",
       "      <td>202312311712</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>202401010000</td>\n",
       "      <td>None</td>\n",
       "      <td>NONE</td>\n",
       "      <td>2024010100003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73066 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISSUE        EXPIRE       PRODISS TYPE  DAY THRESHOLD  \\\n",
       "0      198701091200  198701101200  198701080719    C    2      None   \n",
       "1      198701091200  198701101200  198701081731    C    2      None   \n",
       "2      198701161200  198701171200  198701160615    C    1      TSTM   \n",
       "3      198701191200  198701201200  198701180703    C    2      None   \n",
       "4      198701221200  198701231200  198701210800    C    2      None   \n",
       "...             ...           ...           ...  ...  ...       ...   \n",
       "73061  202312311200  202401011200  202312301607    C    2      None   \n",
       "73062  202312311200  202401011200  202312310520    C    1      None   \n",
       "73063  202401011200  202401021200  202312310600    C    2      None   \n",
       "73064  202401021200  202401031200  202312310815    C    3      TSTM   \n",
       "73065  202401011200  202401021200  202312311712    C    2      None   \n",
       "\n",
       "          CATEGORY  CYCLE          DATE  \\\n",
       "0             None      7  198701090000   \n",
       "1             None     17  198701090000   \n",
       "2      CATEGORICAL      6  198701160000   \n",
       "3             None      7  198701190000   \n",
       "4             None      7  198701220000   \n",
       "...            ...    ...           ...   \n",
       "73061         None     17  202312310000   \n",
       "73062         None      6  202312310000   \n",
       "73063         None      7  202401010000   \n",
       "73064  CATEGORICAL      8  202401020000   \n",
       "73065         None     17  202401010000   \n",
       "\n",
       "                                                geometry MAX_CAT  \\\n",
       "0                                                   None    NONE   \n",
       "1                                                   None    NONE   \n",
       "2      POLYGON ((-81.10300 30.60200, -81.08700 30.521...    TSTM   \n",
       "3                                                   None    NONE   \n",
       "4                                                   None    NONE   \n",
       "...                                                  ...     ...   \n",
       "73061                                               None    TSTM   \n",
       "73062                                               None    TSTM   \n",
       "73063                                               None    NONE   \n",
       "73064  POLYGON ((-90.74500 28.71100, -91.08300 28.732...    TSTM   \n",
       "73065                                               None    NONE   \n",
       "\n",
       "          DATE_ORDER  \n",
       "0      1987010900002  \n",
       "1      1987010900003  \n",
       "2      1987011600004  \n",
       "3      1987011900002  \n",
       "4      1987012200002  \n",
       "...              ...  \n",
       "73061  2023123100003  \n",
       "73062  2023123100004  \n",
       "73063  2024010100002  \n",
       "73064  2024010200001  \n",
       "73065  2024010100003  \n",
       "\n",
       "[73066 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: create master function that subsets data based on easy inputs once it's all been labelled. Put in a util file\n",
    "outlooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
