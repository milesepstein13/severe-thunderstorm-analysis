{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_filter import *\n",
    "from utils_datetime import *\n",
    "from utils_geography import *\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "# TODO: 201804020000's day 3 forecasts are issued on 04/30--in reality, these forecasts were probably meant for 05/02. todo is clean for this sort of thing. Potentially in cleaning file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsets outlooks, pph, and report data in various ways (add label to each datapoint for each method of subsetting so can be pulled out of full dataset later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading outlooks 1\n",
      "reading outlooks 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miles\\OneDrive\\Documents\\UW\\Research\\utils_filter.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outlooks = outlooks.append(gp.read_file(data_location + '/outlooks/' + mod_string + '_outlooks_2.shp'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading pph\n",
      "reading storm reports\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "data_location = 'data'\n",
    "labelled = False # if starting with already labelled data\n",
    "outlooks, pph, reports = read_datasets(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_conversions = {'PST': timedelta(hours=8),\n",
    "                  'MST': timedelta(hours=7),\n",
    "                  'CST': timedelta(hours=6),\n",
    "                  'CSt': timedelta(hours=6),\n",
    "                  'CSC': timedelta(hours=6),\n",
    "                  'SCT': timedelta(hours=6),\n",
    "                  'EST': timedelta(hours=5),\n",
    "                  'ESt': timedelta(hours=5),\n",
    "                  'PDT': timedelta(hours=7),\n",
    "                  'MDT': timedelta(hours=6),\n",
    "                  'CDT': timedelta(hours=5),\n",
    "                  'EDT': timedelta(hours=4),\n",
    "                  'HST': timedelta(hours=10),\n",
    "                  'SST': timedelta(hours=11),\n",
    "                  'GST': timedelta(hours=10),\n",
    "                  'AKS': timedelta(hours=9),\n",
    "                  'AST': timedelta(hours=4),\n",
    "                  'UNK': timedelta(hours=5),\n",
    "                  'GMT': timedelta(0)}\n",
    "\n",
    "def get_reports_date_strings(date_times, timezones):\n",
    "    # returns list of strings of date of given datetime and timezone (where day cutoffs are 12-12 UTC) formatted as 'YYYYMMDD0000'\n",
    "    for datetime, timezone, i in zip(date_times, timezones, range(len(timezones))):\n",
    "        #print(datetime + ' ' + timezone[:3])\n",
    "        datetime = parser.parse(datetime)\n",
    "        datetime = datetime + tz_conversions[timezone[:3]]\n",
    "        #print(datetime)\n",
    "        if (datetime.hour < 12):\n",
    "            datetime = datetime - timedelta(days = 1)\n",
    "        if datetime.year > 2049:\n",
    "            datetime = datetime - relativedelta(years = 100)\n",
    "        datetime = datetime.strftime(\"%Y%m%d\") + '0000'\n",
    "        if i == 0:\n",
    "            ret = [datetime]\n",
    "        else:\n",
    "            ret.append(datetime)\n",
    "    return ret\n",
    "\n",
    "def get_pph_date_strings(times):\n",
    "    # returns a list of strings of given dates formatted as 'YYYYMMDD0000'\n",
    "    for datetime, i in zip(times, range(len(times))):\n",
    "        string = datetime.dt.strftime(\"%Y%m%d\").values + '0000'\n",
    "        if i == 0:\n",
    "            ret = [string]\n",
    "        else:\n",
    "            ret.append(string)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISSUE</th>\n",
       "      <th>EXPIRE</th>\n",
       "      <th>PRODISS</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>DAY</th>\n",
       "      <th>THRESHOLD</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>CYCLE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198701011200</td>\n",
       "      <td>198701021200</td>\n",
       "      <td>198701010635</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>198701010000</td>\n",
       "      <td>MULTIPOLYGON (((-80.69500 29.36500, -80.68200 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198701011500</td>\n",
       "      <td>198701021200</td>\n",
       "      <td>198701011441</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>198701010000</td>\n",
       "      <td>POLYGON ((-70.15100 42.90900, -70.14600 42.899...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198701011900</td>\n",
       "      <td>198701021200</td>\n",
       "      <td>198701011849</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>198701010000</td>\n",
       "      <td>POLYGON ((-73.73200 39.90700, -73.73200 39.892...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198701021200</td>\n",
       "      <td>198701031200</td>\n",
       "      <td>198701020637</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>198701020000</td>\n",
       "      <td>POLYGON ((-124.43300 41.91800, -124.44100 41.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198701031200</td>\n",
       "      <td>198701041200</td>\n",
       "      <td>198701020725</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>198701030000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183180</th>\n",
       "      <td>202401021200</td>\n",
       "      <td>202401031200</td>\n",
       "      <td>202312310815</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>8</td>\n",
       "      <td>202401020000</td>\n",
       "      <td>POLYGON ((-90.74500 28.71100, -91.08300 28.732...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183181</th>\n",
       "      <td>202312311300</td>\n",
       "      <td>202401011200</td>\n",
       "      <td>202312311236</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>202312310000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183182</th>\n",
       "      <td>202312311630</td>\n",
       "      <td>202401011200</td>\n",
       "      <td>202312311558</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>202312310000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183183</th>\n",
       "      <td>202401011200</td>\n",
       "      <td>202401021200</td>\n",
       "      <td>202312311712</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>202401010000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183184</th>\n",
       "      <td>202312312000</td>\n",
       "      <td>202401011200</td>\n",
       "      <td>202312311950</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>202312310000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366370 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ISSUE        EXPIRE       PRODISS TYPE  DAY THRESHOLD  \\\n",
       "0       198701011200  198701021200  198701010635    C    1      TSTM   \n",
       "1       198701011500  198701021200  198701011441    C    1      TSTM   \n",
       "2       198701011900  198701021200  198701011849    C    1      TSTM   \n",
       "3       198701021200  198701031200  198701020637    C    1      TSTM   \n",
       "4       198701031200  198701041200  198701020725    C    2      None   \n",
       "...              ...           ...           ...  ...  ...       ...   \n",
       "183180  202401021200  202401031200  202312310815    C    3      TSTM   \n",
       "183181  202312311300  202401011200  202312311236    C    1      None   \n",
       "183182  202312311630  202401011200  202312311558    C    1      None   \n",
       "183183  202401011200  202401021200  202312311712    C    2      None   \n",
       "183184  202312312000  202401011200  202312311950    C    1      None   \n",
       "\n",
       "           CATEGORY  CYCLE          DATE  \\\n",
       "0       CATEGORICAL     -1  198701010000   \n",
       "1       CATEGORICAL     -1  198701010000   \n",
       "2       CATEGORICAL     -1  198701010000   \n",
       "3       CATEGORICAL     -1  198701020000   \n",
       "4              None     -1  198701030000   \n",
       "...             ...    ...           ...   \n",
       "183180  CATEGORICAL      8  202401020000   \n",
       "183181         None     13  202312310000   \n",
       "183182         None     16  202312310000   \n",
       "183183         None     17  202401010000   \n",
       "183184         None     20  202312310000   \n",
       "\n",
       "                                                 geometry  \n",
       "0       MULTIPOLYGON (((-80.69500 29.36500, -80.68200 ...  \n",
       "1       POLYGON ((-70.15100 42.90900, -70.14600 42.899...  \n",
       "2       POLYGON ((-73.73200 39.90700, -73.73200 39.892...  \n",
       "3       POLYGON ((-124.43300 41.91800, -124.44100 41.9...  \n",
       "4                                                    None  \n",
       "...                                                   ...  \n",
       "183180  POLYGON ((-90.74500 28.71100, -91.08300 28.732...  \n",
       "183181                                               None  \n",
       "183182                                               None  \n",
       "183183                                               None  \n",
       "183184                                               None  \n",
       "\n",
       "[366370 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dates to reports and pph in same format as in outlooks\n",
    "if labelled == False:\n",
    "    reports['DATE'] = get_reports_date_strings(reports['BEGIN_DATE_TIME'], reports['CZ_TIMEZONE']) \n",
    "    pph['time'] = get_pph_date_strings(pph.time) \n",
    "    # subset outlooks into only one day 1, two day 2, and one day 3 categorical outlooks \n",
    "    # day 3: cycle not -1. day 2: cycle not -1. Day 1: cycle 6. Category: categorical.\n",
    "    outlooks = outlooks[(((outlooks['DAY'] == 1) & (outlooks['CYCLE'] == 6)) | ((outlooks['DAY'] == 2) & (outlooks['CYCLE'] != -1)) | ((outlooks['DAY'] == 3) & (outlooks['CYCLE'] != -1)))\n",
    "            & (outlooks['CATEGORY'] == 'CATEGORICAL')]\n",
    "\n",
    "    # reset incicies\n",
    "    outlooks = outlooks.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISSUE</th>\n",
       "      <th>EXPIRE</th>\n",
       "      <th>PRODISS</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>DAY</th>\n",
       "      <th>THRESHOLD</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>CYCLE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198701161200</td>\n",
       "      <td>198701171200</td>\n",
       "      <td>198701160615</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>6</td>\n",
       "      <td>198701160000</td>\n",
       "      <td>POLYGON ((-81.10300 30.60200, -81.08700 30.521...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198701271200</td>\n",
       "      <td>198701281200</td>\n",
       "      <td>198701270643</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>6</td>\n",
       "      <td>198701270000</td>\n",
       "      <td>POLYGON ((-119.01700 33.49500, -119.54500 34.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198701281200</td>\n",
       "      <td>198701291200</td>\n",
       "      <td>198701280631</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>6</td>\n",
       "      <td>198701280000</td>\n",
       "      <td>MULTIPOLYGON (((-123.71244 38.67008, -123.7150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198701291200</td>\n",
       "      <td>198701301200</td>\n",
       "      <td>198701290631</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>6</td>\n",
       "      <td>198701290000</td>\n",
       "      <td>MULTIPOLYGON (((-123.71500 38.67200, -123.7230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198701301200</td>\n",
       "      <td>198701311200</td>\n",
       "      <td>198701300636</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>6</td>\n",
       "      <td>198701300000</td>\n",
       "      <td>POLYGON ((-103.95573 29.30252, -103.97500 29.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62396</th>\n",
       "      <td>202312291200</td>\n",
       "      <td>202312301200</td>\n",
       "      <td>202312290516</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>6</td>\n",
       "      <td>202312290000</td>\n",
       "      <td>POLYGON ((-121.88000 34.66000, -122.05900 34.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62397</th>\n",
       "      <td>202312301200</td>\n",
       "      <td>202312311200</td>\n",
       "      <td>202312290600</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>7</td>\n",
       "      <td>202312300000</td>\n",
       "      <td>POLYGON ((-119.53500 33.98700, -120.06600 33.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62398</th>\n",
       "      <td>202312311200</td>\n",
       "      <td>202401011200</td>\n",
       "      <td>202312290818</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>8</td>\n",
       "      <td>202312310000</td>\n",
       "      <td>POLYGON ((-92.16400 29.18100, -92.62900 29.233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62399</th>\n",
       "      <td>202312301200</td>\n",
       "      <td>202312311200</td>\n",
       "      <td>202312291644</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>17</td>\n",
       "      <td>202312300000</td>\n",
       "      <td>POLYGON ((-119.53500 33.98700, -120.06600 33.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62400</th>\n",
       "      <td>202401021200</td>\n",
       "      <td>202401031200</td>\n",
       "      <td>202312310815</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>TSTM</td>\n",
       "      <td>CATEGORICAL</td>\n",
       "      <td>8</td>\n",
       "      <td>202401020000</td>\n",
       "      <td>POLYGON ((-90.74500 28.71100, -91.08300 28.732...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62401 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISSUE        EXPIRE       PRODISS TYPE  DAY THRESHOLD  \\\n",
       "0      198701161200  198701171200  198701160615    C    1      TSTM   \n",
       "1      198701271200  198701281200  198701270643    C    1      TSTM   \n",
       "2      198701281200  198701291200  198701280631    C    1      TSTM   \n",
       "3      198701291200  198701301200  198701290631    C    1      TSTM   \n",
       "4      198701301200  198701311200  198701300636    C    1      TSTM   \n",
       "...             ...           ...           ...  ...  ...       ...   \n",
       "62396  202312291200  202312301200  202312290516    C    1      TSTM   \n",
       "62397  202312301200  202312311200  202312290600    C    2      TSTM   \n",
       "62398  202312311200  202401011200  202312290818    C    3      TSTM   \n",
       "62399  202312301200  202312311200  202312291644    C    2      TSTM   \n",
       "62400  202401021200  202401031200  202312310815    C    3      TSTM   \n",
       "\n",
       "          CATEGORY  CYCLE          DATE  \\\n",
       "0      CATEGORICAL      6  198701160000   \n",
       "1      CATEGORICAL      6  198701270000   \n",
       "2      CATEGORICAL      6  198701280000   \n",
       "3      CATEGORICAL      6  198701290000   \n",
       "4      CATEGORICAL      6  198701300000   \n",
       "...            ...    ...           ...   \n",
       "62396  CATEGORICAL      6  202312290000   \n",
       "62397  CATEGORICAL      7  202312300000   \n",
       "62398  CATEGORICAL      8  202312310000   \n",
       "62399  CATEGORICAL     17  202312300000   \n",
       "62400  CATEGORICAL      8  202401020000   \n",
       "\n",
       "                                                geometry  \n",
       "0      POLYGON ((-81.10300 30.60200, -81.08700 30.521...  \n",
       "1      POLYGON ((-119.01700 33.49500, -119.54500 34.0...  \n",
       "2      MULTIPOLYGON (((-123.71244 38.67008, -123.7150...  \n",
       "3      MULTIPOLYGON (((-123.71500 38.67200, -123.7230...  \n",
       "4      POLYGON ((-103.95573 29.30252, -103.97500 29.3...  \n",
       "...                                                  ...  \n",
       "62396  POLYGON ((-121.88000 34.66000, -122.05900 34.8...  \n",
       "62397  POLYGON ((-119.53500 33.98700, -120.06600 33.9...  \n",
       "62398  POLYGON ((-92.16400 29.18100, -92.62900 29.233...  \n",
       "62399  POLYGON ((-119.53500 33.98700, -120.06600 33.9...  \n",
       "62400  POLYGON ((-90.74500 28.71100, -91.08300 28.732...  \n",
       "\n",
       "[62401 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_outlooks_label(outlooks, label_dates, labels, label_name, none_label):\n",
    "    # adds new column with values from labels on the corresponding list of dates in label_dates (DONE)\n",
    "    print(\"adding a new column in outlooks\")\n",
    "    outlooks[label_name] = none_label\n",
    "    for label, dates in zip(labels, label_dates):\n",
    "        #print(label)\n",
    "        outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n",
    "    return outlooks\n",
    "\n",
    "def add_pph_label(pph, label_dates, labels, label_name, none_label):\n",
    "    # adds new variable with values from labels on the corresponding list of dates in label_dates (DONE)\n",
    "    print(\"adding new variable in pph\")\n",
    "    pph[label_name] = (('time'), np.full(len(pph['time']), none_label))\n",
    "    for label, dates in zip(labels, label_dates):\n",
    "        #print(label) # TODO: may only be adding first 4 letters of label\n",
    "        pph[label_name].loc[pph['time'].isin(dates)] = label  \n",
    "    return pph\n",
    "\n",
    "def add_reports_label(reports, label_dates, labels, label_name, none_label):\n",
    "    # adds new column with values from labels on the corresponding list of dates in label_dates (DONE)\n",
    "    reports[label_name] = none_label\n",
    "    print(\"adding a new column in reports\")\n",
    "    for label, dates in zip(labels, label_dates):\n",
    "       #print(label)\n",
    "       reports[label_name].loc[reports['DATE'].isin(dates)] = label #\n",
    "    return reports\n",
    "\n",
    "def add_labels(outlooks, pph, reports, label_dates, labels, label_name, none_label):\n",
    "    # adds labels, overwriting with later ones if a date has multiple labels\n",
    "    return(add_outlooks_label(outlooks, label_dates, labels, label_name, none_label), \n",
    "           add_pph_label(pph, label_dates, labels, label_name, none_label),\n",
    "           add_reports_label(reports, label_dates, labels, label_name, none_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_outlooks = outlooks\n",
    "new_pph = pph\n",
    "new_reports = reports.drop(columns=['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALWAYS RUN THROUGH HERE. THEN TO ADD MORE LABELS, RUN JUST THE LABELLING YOU WISH TO BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in reports\n"
     ]
    }
   ],
   "source": [
    "# add max threshold forecasted for valid day to each datapoint\n",
    "\n",
    "categories = ['TSTM', 'MRGL', 'SLGT', 'ENH', 'MDT', 'HIGH']\n",
    "category_dates = []\n",
    "for category in categories:\n",
    "    category_dates.append(identify_dates_above_threshold(new_outlooks, category))\n",
    "\n",
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, category_dates, categories, 'MAX_CAT', 'NONE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by ramp up/down amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put new_outlooks in correct order\n",
    "\n",
    "new_outlooks['DATE_ORDER'] = 0\n",
    "for index, row in new_outlooks.iterrows():\n",
    "    if row['DAY'] == 3:\n",
    "        new_outlooks.at[index, 'DATE_ORDER'] = row['DATE'] + '1'\n",
    "    elif row['DAY'] == 1:\n",
    "        new_outlooks.at[index, 'DATE_ORDER'] = row['DATE'] + '4'\n",
    "    elif row['CYCLE'] == 7:\n",
    "        new_outlooks.at[index, 'DATE_ORDER'] = row['DATE'] + '2'\n",
    "    else:\n",
    "        new_outlooks.at[index, 'DATE_ORDER'] = row['DATE'] + '3'\n",
    "new_outlooks = new_outlooks.sort_values('DATE_ORDER')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_3_cutoff(outlooks):\n",
    "    # returns list of dates in outlooks \n",
    "    return outlooks[outlooks['DAY'] == 3]['DATE'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ramp_lists(outlooks, category_dict):\n",
    "\n",
    "    first_day_3 = get_day_3_cutoff(outlooks)\n",
    "    first_day_2_1 = '199707100000'\n",
    "    first_day_2_2 = '199504040000'\n",
    "\n",
    "    ramp_ups = {\n",
    "        0: [],\n",
    "        1: [],\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: [],\n",
    "        6: []\n",
    "    }\n",
    "\n",
    "    ramp_downs = {\n",
    "        0: [],\n",
    "        -1: [],\n",
    "        -2: [],\n",
    "        -3: [],\n",
    "        -4: [],\n",
    "        -5: [],\n",
    "        -6: []\n",
    "    }\n",
    "\n",
    "    ramp_categories = {\n",
    "        'up': [],\n",
    "        'down': [],\n",
    "        'both': [],\n",
    "        'neither': []\n",
    "    }\n",
    "\n",
    "    old_date = '0'\n",
    "    old_do = '0'\n",
    "    first = True\n",
    "\n",
    "    for index, row in outlooks.iterrows(): #iterrating through each polygon in the outlook dataset\n",
    "        cat = category_dict[row['THRESHOLD']]\n",
    "        do = row['DATE_ORDER']\n",
    "        date = row['DATE']\n",
    "\n",
    "        if date != old_date: # New date, save ramp up and ramp down and save alongside old date, then reset ramps, max and min categories seen, and do threshold\n",
    "            \n",
    "            \n",
    "            if first == True:\n",
    "                first = False\n",
    "            else:\n",
    "\n",
    "                if max_cat_do - min_cat_date > ramp_up:\n",
    "                    ramp_up = max_cat_do - min_cat_date\n",
    "                if max_cat_do - max_cat_date < ramp_down:\n",
    "                    ramp_down = max_cat_do - max_cat_date\n",
    "\n",
    "                if max_cat_do > max_cat_date:\n",
    "                    max_cat_date = max_cat_do\n",
    "                if max_cat_do < min_cat_date:\n",
    "                    min_cat_date = max_cat_do\n",
    "\n",
    "                ramp_ups[ramp_up].append(old_date)\n",
    "                ramp_downs[ramp_down].append(old_date)\n",
    "                if ramp_up > 0 and ramp_down < 0:\n",
    "                    ramp_categories['both'].append(old_date)\n",
    "                elif ramp_up > 0:\n",
    "                    ramp_categories['up'].append(old_date)\n",
    "                elif ramp_down < 0:\n",
    "                    ramp_categories['down'].append(old_date)\n",
    "                else:\n",
    "                    ramp_categories['neither'].append(old_date)\n",
    "\n",
    "            old_date = date\n",
    "            old_do = do\n",
    "            \n",
    "            ramp_down = 0\n",
    "            ramp_up = 0\n",
    "            max_cat_date = -1\n",
    "            \n",
    "            # TODO: consider other changes to forecast practices\n",
    "            if date > first_day_3 and do[-1] == '1': # Since 2002\n",
    "                min_cat_date = 5 \n",
    "            elif date > first_day_2_1 and (do[-1] == '2' or do[-1] == '1'): # Since 1997. Check for 1 is in case there is an earlier forecast issued.\n",
    "                min_cat_date = 5 \n",
    "            elif date > first_day_2_2 and (do[-1] == '3' or do[-1] == '2' or do[-1] == '1'): # Since 1995\n",
    "                min_cat_date = 5 \n",
    "            elif date <= first_day_2_2:\n",
    "                min_cat_date = 5\n",
    "            else:\n",
    "                min_cat_date = -1 # The first outlook on this date was not the earliest forecast it could have been, so it ramped up from no forecast\n",
    "\n",
    "            max_cat_do = cat\n",
    "\n",
    "\n",
    "        elif do != old_do: # new outlook, update min and max categories seen, ramp value\n",
    "            if max_cat_do - min_cat_date > ramp_up:\n",
    "                ramp_up = max_cat_do - min_cat_date\n",
    "            if max_cat_do - max_cat_date < ramp_down:\n",
    "                ramp_down = max_cat_do - max_cat_date\n",
    "\n",
    "            if max_cat_do > max_cat_date:\n",
    "                max_cat_date = max_cat_do\n",
    "            if max_cat_do < min_cat_date:\n",
    "                min_cat_date = max_cat_do\n",
    "\n",
    "            old_do = do\n",
    "\n",
    "            max_cat_do = cat\n",
    "\n",
    "        else: # Just another threshold within the same polygon\n",
    "            if cat > max_cat_do:\n",
    "                max_cat_do = cat\n",
    "            \n",
    "        \n",
    "    # for last iteration\n",
    "    ramp_ups[ramp_up].append(old_date)\n",
    "    ramp_downs[ramp_down].append(old_date)\n",
    "    if ramp_up > 0 and ramp_down < 0:\n",
    "        ramp_categories['both'].append(old_date)\n",
    "    elif ramp_up > 0:\n",
    "        ramp_categories['up'].append(old_date)\n",
    "    elif ramp_down < 0:\n",
    "        ramp_categories['down'].append(old_date)\n",
    "    else:\n",
    "        ramp_categories['neither'].append(old_date)\n",
    "\n",
    "    return(ramp_ups, ramp_downs, ramp_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and add ramp category for each datapoint. Potentially add 2 binary ramp up and ramp down (4 options are [up, down, up and down, niether]). How many forecasts to consider for each day? The day 3, both day 2, and the first day 1 (so 4 forecasts ramp)\n",
    "# dictionary of category to number\n",
    "category_dict = {\n",
    "    None : -1,\n",
    "    'NONE' : -1,\n",
    "    'TSTM': 0,\n",
    "    'MRGL': 1,\n",
    "    'SLGT': 2,\n",
    "    'ENH': 3,\n",
    "    'MDT': 4,\n",
    "    'HIGH': 5\n",
    "}\n",
    "\n",
    "(ramp_ups, ramp_downs, ramp_categories) = create_ramp_lists(new_outlooks, category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n",
      "adding a new column in reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n",
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reports[label_name].loc[reports['DATE'].isin(dates)] = label #\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n",
      "adding a new column in reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n",
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reports[label_name].loc[reports['DATE'].isin(dates)] = label #\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n",
      "adding a new column in reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n",
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reports[label_name].loc[reports['DATE'].isin(dates)] = label #\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ramp up\n",
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, list(ramp_ups.values()), ramp_ups.keys(), 'RAMP_UP', 0)\n",
    "\n",
    "# ramp down\n",
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, list(ramp_downs.values()), ramp_downs.keys(), 'RAMP_DOWN', 0)\n",
    "\n",
    "# ramp categories\n",
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, list(ramp_categories.values()), ramp_categories.keys(), 'RAMP_CATEGORIES', 'neither')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by accurate/inaccurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider forecast issue time for day 1--subset reports (and revise pph?)--look at other studies to see how they handled multiple day 1 outlooks (see the one in slack). Starting point should be use first forecasts, later ones would be a different analysis for another time. Decide if we should denote these somehow.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_dates(pph):\n",
    "    dates = list(set(pph['time'].values))\n",
    "    season_dates = [[], [], [], []]\n",
    "    for date in dates:\n",
    "        month = int(date[4:6])\n",
    "        if month == 12 or month < 3:\n",
    "            season_dates[0].append(date)\n",
    "        elif month < 6:\n",
    "            season_dates[1].append(date)\n",
    "        elif month < 9:\n",
    "            season_dates[2].append(date)\n",
    "        else:\n",
    "            season_dates[3].append(date)\n",
    "    return season_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n",
      "adding a new column in reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n",
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reports[label_name].loc[reports['DATE'].isin(dates)] = label #\n"
     ]
    }
   ],
   "source": [
    "# add column denoting season (4 met seasons as starting point)\n",
    "\n",
    "seasons = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "season_dates = get_season_dates(new_pph)\n",
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, season_dates, seasons, 'SEASON', 'xxxxxx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide how to do... lower priotity, could do by state of center of highest category (or center of PPH?) Could start with super basic version\n",
    "# same regions as Anderson-Frey 2016\n",
    "# center is grid square with highest p_perfect prob of at least one hazard (assuming each hazard in independent)\n",
    "\n",
    "# practically perfect probability of at least one hazard occuring near datapoint\n",
    "new_pph['p_perfect_total'] = (1 - (1-new_pph['p_perfect_wind']/100)*(1-new_pph['p_perfect_hail']/100)*(1-new_pph['p_perfect_tor']/100))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect regions in chunks (since doing it all at once can time out)\n",
    "regions = {\n",
    "        'West': [],\n",
    "        'Midwest': [],\n",
    "        'Great Plains': [],\n",
    "        'Northeast': [],\n",
    "        'South': [],\n",
    "        'NONE': []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(lat, lon, geolocator):\n",
    "    location = geolocator.reverse(str(lat)+\",\"+str(lon))\n",
    "    if location == None:\n",
    "        return None\n",
    "    address = location.raw['address']\n",
    "    state = address.get('state', '')\n",
    "    return state\n",
    "\n",
    "def get_region(lat, lon, west_threshold_co_nm, regions_dict, geolocator):\n",
    "    state = get_state(lat, lon, geolocator)\n",
    "    if state == 'Colorado' or state == 'New Mexico':\n",
    "        if lon < west_threshold_co_nm:\n",
    "            return('West')\n",
    "        else:\n",
    "            return('Great Plains')\n",
    "    for region in regions_dict:\n",
    "        if state in regions_dict[region]:\n",
    "            return region\n",
    "    # Cases where highest PPH is out of contiguous states, usually just outside bc nearest gridpoint is on other side of border\n",
    "    if lat > 38:\n",
    "        if lon > -80.5:\n",
    "            return('Northeast')\n",
    "        elif lon > -104:\n",
    "            return('Great Plains')\n",
    "        else:\n",
    "            return('West')\n",
    "    else:\n",
    "        if lon > -93.8:\n",
    "            return('South')\n",
    "        elif lon > -106.5:\n",
    "            return('Great Plains')\n",
    "        else:\n",
    "            return('West')\n",
    "    return('NONE')\n",
    "\n",
    "\n",
    "def create_regions(pph):\n",
    "    regions = {\n",
    "        'West': [],\n",
    "        'Midwest': [],\n",
    "        'Great Plains': [],\n",
    "        'Northeast': [],\n",
    "        'South': [],\n",
    "        'NONE': []\n",
    "    }\n",
    "\n",
    "    geolocator = Nominatim(user_agent=\"severe_thunderstorm_miles\")\n",
    "    west_threshold_co_nm = -105\n",
    "    regions_dict = { # list of states fully within each region (doesn't include AK, HI, CO, NM)\n",
    "        'West': ['Washington', 'Oregon', 'California', 'Idaho', 'Montana', 'Wyoming', 'Utah', 'Arizona'],\n",
    "        'Midwest': ['North Dakota', 'South Dakota', 'Minnesota', 'Iowa', 'Wisconsin', 'Illinois', 'Michigan', 'Indiana', 'Ohio', 'Kentucky'],\n",
    "        'Great Plains': ['Nebraska', 'Kansas', 'Oklahoma', 'Texas', 'Missouri'],\n",
    "        'Northeast': ['Maine', 'Vermont', 'New Hampshire', 'Massachusetts', 'Rhode Island', 'Connecticut', 'New York', 'Pennsylvania', 'New Jersey', 'Delaware', 'Maryland', 'District of Columbia', 'West Virginia'],\n",
    "        'South': ['Virginia', 'Arkansas', 'Louisiana', 'Tennessee', 'Mississippi', 'Alabama', 'Georgia', 'North Carolina', 'South Carolina', 'Florida']\n",
    "    }\n",
    "\n",
    "    old_year = ''\n",
    "    for date, date_pph in pph.groupby('time'):\n",
    "        if date_pph['p_perfect_total'].max() > 0:\n",
    "            year = date[0:4]\n",
    "            if year != old_year:\n",
    "                print(\"Finding regions for \" + year)\n",
    "                old_year = year\n",
    "            max_coords = date_pph['p_perfect_total'].argmax(dim = ['x', 'y'])\n",
    "            max_x_coord = max_coords['x'].values\n",
    "            max_y_coord = max_coords['y'].values\n",
    "            lat = date_pph['lat'].loc[dict(x = max_x_coord, y = max_y_coord)].values\n",
    "            lon = date_pph['lon'].loc[dict(x = max_x_coord, y = max_y_coord)].values\n",
    "            region = get_region(lat, lon, west_threshold_co_nm, regions_dict, geolocator)\n",
    "            regions[region].append(date)\n",
    "            \n",
    "    return(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding regions for 1987\n",
      "Finding regions for 1988\n",
      "Finding regions for 1989\n",
      "Finding regions for 1990\n",
      "Finding regions for 1991\n",
      "Finding regions for 1992\n",
      "Added chunk 2 to regions\n"
     ]
    }
   ],
   "source": [
    "chunks = 10\n",
    "time_array = new_pph['time']\n",
    "chunk_size = math.ceil(len(time_array)/chunks)\n",
    "time_arrays = [time_array[i:i + chunk_size] for i in range(0, len(time_array), chunk_size)]\n",
    "for i in range(2, 3):\n",
    "    chunk_regions = create_regions(new_pph.sel(time = time_arrays[i]))\n",
    "    for region in regions:\n",
    "        regions[region] += chunk_regions[region]\n",
    "    print('Added chunk ' + str(i) + ' to regions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reports[label_name].loc[reports['DATE'].isin(dates)] = label #\n"
     ]
    }
   ],
   "source": [
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, list(regions.values()), regions.keys(), 'REGION', 'NONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset by environmental data (to do later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label by max total pph bin and count of storm reports (very rudamentary methods of accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n",
      "adding new variable in pph\n",
      "adding a new column in reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n",
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reports[label_name].loc[reports['DATE'].isin(dates)] = label #\n"
     ]
    }
   ],
   "source": [
    "# max p_perfect_total\n",
    "max_total_pph = { # TODO: see if categories or cutoffs are correct here from SPC\n",
    "    'HIGH': [],\n",
    "    'MDT': [],\n",
    "    'ENH': [],\n",
    "    'SLGT': [],\n",
    "    'MRGL': [],\n",
    "    'TSTM': [],\n",
    "    'ZERO': []\n",
    "}\n",
    "\n",
    "for date, date_pph in pph.groupby('time'):\n",
    "    max_pph = date_pph['p_perfect_total'].max()\n",
    "    if max_pph == 0:\n",
    "        max_total_pph['ZERO'].append(date)\n",
    "    elif max_pph < 5:\n",
    "        max_total_pph['TSTM'].append(date)\n",
    "    elif max_pph < 15:\n",
    "        max_total_pph['MRGL'].append(date)\n",
    "    elif max_pph < 30:\n",
    "        max_total_pph['SLGT'].append(date)\n",
    "    elif max_pph < 45:\n",
    "        max_total_pph['ENH'].append(date)\n",
    "    elif max_pph < 60:\n",
    "        max_total_pph['MDT'].append(date)\n",
    "    else:\n",
    "        max_total_pph['HIGH'].append(date)\n",
    "    \n",
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, list(max_total_pph.values()), max_total_pph.keys(), 'MAX_PPH', 'NONE')\n",
    "\n",
    "# TODO: also do numerically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of storm reports \n",
    "# should be pretty trivial. Look up function\n",
    "full_dates = reports['DATE']\n",
    "c = Counter(full_dates)\n",
    "report_counts = {\n",
    "    0: []\n",
    "}\n",
    "for date, count in c.items():\n",
    "    if count in report_counts:\n",
    "        report_counts[count].append(date)\n",
    "    else:\n",
    "        report_counts[count] = [date]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding a new column in outlooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outlooks[label_name].loc[outlooks['DATE'].isin(dates)] = label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding new variable in pph\n",
      "adding a new column in reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\3803889815.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reports[label_name].loc[reports['DATE'].isin(dates)] = label #\n"
     ]
    }
   ],
   "source": [
    "(new_outlooks, new_pph, new_reports) = add_labels(new_outlooks, new_pph, new_reports, list(report_counts.values()), report_counts.keys(), 'NUM_REPORTS', '0')\n",
    "\n",
    "# TODO: bin this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONCE YOU ADD THE LABELS YOU WANT, SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20848\\1329507236.py:6: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  new_outlooks.to_file(outlook_save_location + '/labelled_outlooks.shp')\n"
     ]
    }
   ],
   "source": [
    "# resave labelled data\n",
    "outlook_save_location = 'data/outlooks'\n",
    "pph_save_location = 'data/pph'\n",
    "report_save_location = 'data/storm_reports'\n",
    "\n",
    "new_outlooks.to_file(outlook_save_location + '/labelled_outlooks.shp')\n",
    "new_pph.to_netcdf(pph_save_location + '/labelled_pph.nc')\n",
    "new_reports.to_csv(report_save_location + '/labelled_reports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
