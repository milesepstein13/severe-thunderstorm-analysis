{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import cartopy as cp\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from scipy.ndimage import map_coordinates\n",
    "import metpy.calc as mpcalc\n",
    "from geographiclib.geodesic import Geodesic\n",
    "from utils_datetime import *\n",
    "from utils_filter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script calculates the displacement vector fields between outlook and pph probability fields, using optical flow tracking algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 'data'\n",
    "pph = xr.open_dataset('data/pph/labelled2023_pph.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlooks = xr.open_dataset('data/outlooks/grid_outlooks2.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geod = Geodesic.WGS84\n",
    "\n",
    "def flow_day(outlook_array, pph_array, lons, lats):\n",
    "    # returns arrays of x-flow and y-flow (units of grid squares), ending lon and lat, and east/west components of flow (units of m)\n",
    "    # plots use end lon/lat, divergence uses grid square units, shifts use east/west components\n",
    "    end_lons = np.empty_like(outlook_array)\n",
    "    end_lats = np.empty_like(outlook_array)\n",
    "    e_flow = np.empty_like(outlook_array)\n",
    "    n_flow = np.empty_like(outlook_array)\n",
    "    flow = cv.calcOpticalFlowFarneback(outlook_array, pph_array, None, .5, 3, 3, 3, 7, 1.5, 0)\n",
    "    for i in range(lons.shape[0]):\n",
    "        for j in range(lats.shape[1]):\n",
    "            end_lon = map_coordinates(lons, [[i + flow[i, j, 1]], [j + flow[i, j, 0]]])\n",
    "            end_lat = map_coordinates(lats, [[i + flow[i, j, 1]], [j + flow[i, j, 0]]])\n",
    "            if end_lon == 0:\n",
    "                end_lon = lons[i, j]\n",
    "            if end_lat == 0:\n",
    "                end_lat = lats[i, j]\n",
    "            end_lons[i, j] = end_lon\n",
    "            end_lats[i, j] = end_lat\n",
    "            g = geod.Inverse(lats[i, j], lons[i, j], end_lat, end_lon)\n",
    "            dist = g['s12']\n",
    "            azimuth = g['azi1']\n",
    "            e_flow[i, j] = dist * np.sin(np.deg2rad(azimuth))\n",
    "            n_flow[i, j] = dist * np.cos(np.deg2rad(azimuth))\n",
    "\n",
    "    return(flow[..., 0], flow[..., 1], end_lons, end_lats, e_flow, n_flow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN IF ADDING ON\n",
    "hazard_types= ['Wind', 'Hail', 'Tornado', 'All Hazard']\n",
    "displacement_dataset = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        lat=(['y', 'x'], pph['lat'].data),\n",
    "        lon=(['y', 'x'], pph['lon'].data)\n",
    "    ),\n",
    "    coords=dict(\n",
    "        time=(['time'], pph['time'].data),\n",
    "        x=(['x'], pph['x'].data),\n",
    "        y=(['y'], pph['y'].data),\n",
    "        hazard=(['hazard'], hazard_types)\n",
    "    ),\n",
    "    attrs=dict(description=\"Displacements from gridded day 1 probabilistic outlooks to gridded probabilistic PPH using Farnebeck optical flow\",\n",
    "            grid = pph.grid),\n",
    ")\n",
    "\n",
    "displacement_dataset = displacement_dataset.assign(x_flow = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(y_flow = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(end_lon = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(end_lat = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(e_flow = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(n_flow = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displacement_dataset = xr.open_dataset('data/displacement/displacements.nc')\n",
    "hazard_types= ['Wind', 'Hail', 'Tornado', 'All Hazard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pph_key_dict = {\n",
    "    'Wind': 'p_perfect_wind',\n",
    "    'Hail': 'p_perfect_hail',\n",
    "    'Tornado': 'p_perfect_tor',\n",
    "    'All Hazard': 'p_perfect_totalsvr'\n",
    "}\n",
    "\n",
    "outlook_key_dict = {\n",
    "    'Wind': 'Day 1 Wind',\n",
    "    'Hail': 'Day 1 Hail',\n",
    "    'Tornado': 'Day 1 Tornado',\n",
    "    'All Hazard': 'Day 1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197901\n",
      "197902\n",
      "197903\n",
      "197904\n",
      "197905\n",
      "197906\n",
      "197907\n"
     ]
    }
   ],
   "source": [
    "lons =  pph.lon.values\n",
    "lats = pph.lat.values\n",
    "oldyear = 0\n",
    "\n",
    "for time in displacement_dataset['time']: #[displacement_dataset['time'] < '200203310000']:\n",
    "    year = str(time.values)[:6]\n",
    "    if year != oldyear:\n",
    "        displacement_dataset.to_netcdf('data/displacement/displacements2.nc')\n",
    "        oldyear = year\n",
    "        print(year)\n",
    "    for hazard in hazard_types: \n",
    "        pph_array = pph.sel(time = time)[pph_key_dict[hazard]].data*2.55 # normalize to 8-bit image scale\n",
    "        outlook_array = outlooks.sel(time = time, outlook = outlook_key_dict[hazard])['prob'].data*255 # normalize to 8-bit image scale\n",
    "        x_flow, y_flow, end_lons, end_lats, e_flow, n_flow = flow_day(outlook_array, pph_array, lons, lats)\n",
    "\n",
    "        displacement_dataset['x_flow'].loc[dict(time = time, hazard = hazard)] = x_flow\n",
    "        displacement_dataset['y_flow'].loc[dict(time = time, hazard = hazard)] = y_flow\n",
    "        displacement_dataset['end_lon'].loc[dict(time = time, hazard = hazard)] = end_lons\n",
    "        displacement_dataset['end_lat'].loc[dict(time = time, hazard = hazard)] = end_lats\n",
    "        displacement_dataset['e_flow'].loc[dict(time = time, hazard = hazard)] = e_flow\n",
    "        displacement_dataset['n_flow'].loc[dict(time = time, hazard = hazard)] = n_flow\n",
    "    \n",
    "\n",
    "displacement_dataset.to_netcdf('data/displacement/displacements_final.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add shifts, divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_types= ['Wind', 'Hail', 'Tornado', 'All Hazard']\n",
    "\n",
    "displacement_dataset = displacement_dataset.assign(e_shift = (('time', 'hazard'), np.full((len(displacement_dataset['time']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(n_shift = (('time', 'hazard'), np.full((len(displacement_dataset['time']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(total_div = (('time', 'hazard'), np.full((len(displacement_dataset['time']), len(hazard_types)), 0.0)))\n",
    "\n",
    "for hazard in hazard_types:\n",
    "\n",
    "    print(hazard)\n",
    "\n",
    "    e_shifts = []\n",
    "    n_shifts = []\n",
    "    total_divs = []\n",
    "\n",
    "    hazard_dataset = displacement_dataset.sel(hazard = hazard)\n",
    "    for date in displacement_dataset['time']:\n",
    "        weights = outlooks.sel(time = date, outlook = outlook_key_dict[hazard])['prob'].data\n",
    "        if weights.max() == 0: # no outlook, so weight at pph\n",
    "            weights = pph.sel(time = date)[pph_key_dict[hazard]].data\n",
    "        if weights.max() == 0:\n",
    "            weights = None\n",
    "        hazard_time_dataset = hazard_dataset.sel(time = date)\n",
    "        e_shift = np.average(hazard_time_dataset['e_flow'], weights = weights)\n",
    "        n_shift = np.average(hazard_time_dataset['n_flow'], weights = weights)\n",
    "        div = np.gradient(hazard_time_dataset['x_flow'])[1] + np.gradient(hazard_time_dataset['y_flow'])[0]\n",
    "        total_div = np.average(div, weights = weights)\n",
    "\n",
    "        displacement_dataset['e_shift'].loc[dict(time = date, hazard = hazard)] = e_shift\n",
    "        displacement_dataset['n_shift'].loc[dict(time = date, hazard = hazard)] = n_shift\n",
    "        displacement_dataset['total_div'].loc[dict(time = date, hazard = hazard)] = total_div\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacement_dataset.to_netcdf('data/displacement/displacements_final.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date = '201305310000'\n",
    "pph_array = pph.sel(time = test_date)['p_perfect_max'].data/100*255 # normalize to 8-bit image scale\n",
    "outlook_array = outlooks.sel(time = test_date, outlook = 'Day 1')['prob'].data*255 # normalize to 8-bit image scale\n",
    "x_flow, y_flow, end_lons, end_lats, e_flow, n_flow = flow_day(outlook_array, pph_array, pph.lon.values, pph.lat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = pph.lon.values\n",
    "lats = pph.lat.values\n",
    "\n",
    "fig=plt.figure(figsize=(9,6), dpi = 1000)\n",
    "ax = plt.axes(projection = cp.crs.LambertConformal())\n",
    "ax.add_feature(cp.feature.LAND,facecolor='grey')\n",
    "ax.add_feature(cp.feature.OCEAN, alpha = 0.5)\n",
    "ax.add_feature(cp.feature.COASTLINE,linewidth=0.5)\n",
    "ax.add_feature(cp.feature.LAKES, alpha = 0.5)\n",
    "ax.add_feature(cp.feature.STATES,linewidth=0.5)\n",
    "ax.contourf(lons, lats, outlook_array/255,\n",
    "                    levels=[.02,.05,.10,.15,.30,.45,.60,1.00], colors=['#008b00','#8b4726','#ffc800', '#ff0000', '#ff00ff', '#912cee', '#104e8b'], transform=cp.crs.PlateCarree())\n",
    "ax.contour(lons, lats, pph_array/255, levels=[.02,.05,.10,.15,.30,.45,.60,1.00], colors = 'black', linestyles = 'dashed', linewidths = .5, transform=cp.crs.PlateCarree())\n",
    "\n",
    "for i in range(lons.shape[0]):\n",
    "    for j in range(lats.shape[1]):\n",
    "        if np.abs(x_flow[i, j]) > .01 and np.abs(y_flow[i, j]) > .01:\n",
    "            ax.add_patch(FancyArrowPatch((lons[i, j], lats[i, j]), (end_lons[i, j], end_lats[i, j]), transform=cp.crs.PlateCarree(), color = 'black', mutation_scale=4, linewidth = .01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = cv.calcOpticalFlowFarneback(outlook_array, pph_array, None, .5, 3, 3, 3, 7, 1.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: handle weights properly when all zero... think about how to do\n",
    "# weighted mean shift\n",
    "x_shift = np.average(flow[:, :, 0], weights = outlook_array)\n",
    "y_shift = np.average(flow[:, :, 1], weights = outlook_array)\n",
    "x_shift*80, y_shift * 80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted mean divergence, range should be approximately (-1, 1)\n",
    "# try basic method with np.gradient. Will then use metpy gradient but need flow vectors to have proper units first\n",
    "\n",
    "div = np.gradient(flow[:, :, 0])[1] + np.gradient(flow[:, :, 1])[0]\n",
    "total_div = np.average(div, weights = outlook_array)\n",
    "total_div\n",
    "\n",
    "\n",
    "curl = np.gradient(flow[:, :, 0])[0] + np.gradient(flow[:, :, 1])[1]\n",
    "total_curl = np.average(curl, weights = outlook_array)\n",
    "\n",
    "total_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(div)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_displacements = xr.open_dataset('data/displacement/displacements.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
