{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import cartopy as cp\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from scipy.ndimage import map_coordinates\n",
    "import metpy.calc as mpcalc\n",
    "from geographiclib.geodesic import Geodesic\n",
    "from utils_datetime import *\n",
    "from utils_filter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script calculates the displacement vector fields between outlook and pph probability fields, using optical flow tracking algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 'data'\n",
    "pph = xr.open_dataset('data/pph/labelled2023_pph.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlooks = xr.open_dataset('data/outlooks/grid_outlooks2.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geod = Geodesic.WGS84\n",
    "\n",
    "def flow_day(outlook_array, pph_array, lons, lats):\n",
    "    # returns arrays of x-flow and y-flow (units of grid squares), ending lon and lat, and east/west components of flow (units of m)\n",
    "    # plots use end lon/lat, divergence uses grid square units, shifts use east/west components\n",
    "    end_lons = np.empty_like(outlook_array)\n",
    "    end_lats = np.empty_like(outlook_array)\n",
    "    e_flow = np.empty_like(outlook_array)\n",
    "    n_flow = np.empty_like(outlook_array)\n",
    "    flow = cv.calcOpticalFlowFarneback(outlook_array, pph_array, None, .5, 3, 3, 3, 7, 1.5, 0)\n",
    "    for i in range(lons.shape[0]):\n",
    "        for j in range(lats.shape[1]):\n",
    "            end_lon = map_coordinates(lons, [[i + flow[i, j, 1]], [j + flow[i, j, 0]]])\n",
    "            end_lat = map_coordinates(lats, [[i + flow[i, j, 1]], [j + flow[i, j, 0]]])\n",
    "            if end_lon == 0:\n",
    "                end_lon = lons[i, j]\n",
    "            if end_lat == 0:\n",
    "                end_lat = lats[i, j]\n",
    "            end_lons[i, j] = end_lon\n",
    "            end_lats[i, j] = end_lat\n",
    "            g = geod.Inverse(lats[i, j], lons[i, j], end_lat, end_lon)\n",
    "            dist = g['s12']\n",
    "            azimuth = g['azi1']\n",
    "            e_flow[i, j] = dist * np.sin(np.deg2rad(azimuth))\n",
    "            n_flow[i, j] = dist * np.cos(np.deg2rad(azimuth))\n",
    "\n",
    "    return(flow[..., 0], flow[..., 1], end_lons, end_lats, e_flow, n_flow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN IF ADDING ON\n",
    "hazard_types= ['Wind', 'Hail', 'Tornado', 'All Hazard']\n",
    "displacement_dataset = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        lat=(['y', 'x'], pph['lat'].data),\n",
    "        lon=(['y', 'x'], pph['lon'].data)\n",
    "    ),\n",
    "    coords=dict(\n",
    "        time=(['time'], pph['time'].data),\n",
    "        x=(['x'], pph['x'].data),\n",
    "        y=(['y'], pph['y'].data),\n",
    "        hazard=(['hazard'], hazard_types)\n",
    "    ),\n",
    "    attrs=dict(description=\"Displacements from gridded day 1 probabilistic outlooks to gridded probabilistic PPH using Farnebeck optical flow\",\n",
    "            grid = pph.grid),\n",
    ")\n",
    "\n",
    "displacement_dataset = displacement_dataset.assign(x_flow = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(y_flow = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(end_lon = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(end_lat = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(e_flow = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(n_flow = (('time', 'y', 'x', 'hazard'), np.full((len(displacement_dataset['time']), len(displacement_dataset['y']), len(displacement_dataset['x']), len(hazard_types)), 0.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacement_dataset = xr.open_dataset('data/displacement/displacements2.nc')\n",
    "hazard_types= ['Wind', 'Hail', 'Tornado', 'All Hazard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pph_key_dict = {\n",
    "    'Wind': 'p_perfect_wind',\n",
    "    'Hail': 'p_perfect_hail',\n",
    "    'Tornado': 'p_perfect_tor',\n",
    "    'All Hazard': 'p_perfect_totalsvr'\n",
    "}\n",
    "\n",
    "outlook_key_dict = {\n",
    "    'Wind': 'Day 1 Wind',\n",
    "    'Hail': 'Day 1 Hail',\n",
    "    'Tornado': 'Day 1 Tornado',\n",
    "    'All Hazard': 'Day 1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198411\n",
      "198412\n",
      "198501\n",
      "198502\n",
      "198503\n",
      "198504\n",
      "198505\n",
      "198506\n",
      "198507\n",
      "198508\n",
      "198509\n",
      "198510\n",
      "198511\n",
      "198512\n",
      "198601\n",
      "198602\n",
      "198603\n",
      "198604\n",
      "198605\n",
      "198606\n",
      "198607\n",
      "198608\n",
      "198609\n",
      "198610\n",
      "198611\n",
      "198612\n",
      "198701\n",
      "198702\n",
      "198703\n",
      "198704\n",
      "198705\n",
      "198706\n",
      "198707\n",
      "198708\n",
      "198709\n",
      "198710\n",
      "198711\n",
      "198712\n",
      "198801\n",
      "198802\n",
      "198803\n",
      "198804\n",
      "198805\n",
      "198806\n",
      "198807\n",
      "198808\n",
      "198809\n",
      "198810\n",
      "198811\n",
      "198812\n",
      "198901\n",
      "198902\n",
      "198903\n",
      "198904\n",
      "198905\n",
      "198906\n",
      "198907\n",
      "198908\n",
      "198909\n",
      "198910\n",
      "198911\n",
      "198912\n",
      "199001\n",
      "199002\n",
      "199003\n",
      "199004\n",
      "199005\n",
      "199006\n",
      "199007\n",
      "199008\n",
      "199009\n",
      "199010\n",
      "199011\n",
      "199012\n",
      "199101\n",
      "199102\n",
      "199103\n",
      "199104\n",
      "199105\n",
      "199106\n",
      "199107\n",
      "199108\n",
      "199109\n",
      "199110\n",
      "199111\n",
      "199112\n",
      "199201\n",
      "199202\n",
      "199203\n",
      "199204\n",
      "199205\n",
      "199206\n",
      "199207\n",
      "199208\n",
      "199209\n",
      "199210\n",
      "199211\n",
      "199212\n",
      "199301\n",
      "199302\n",
      "199303\n",
      "199304\n",
      "199305\n",
      "199306\n",
      "199307\n",
      "199308\n",
      "199309\n",
      "199310\n",
      "199311\n",
      "199312\n",
      "199401\n",
      "199402\n",
      "199403\n",
      "199404\n",
      "199405\n",
      "199406\n",
      "199407\n",
      "199408\n",
      "199409\n",
      "199410\n",
      "199411\n",
      "199412\n",
      "199501\n",
      "199502\n",
      "199503\n",
      "199504\n",
      "199505\n",
      "199506\n",
      "199507\n",
      "199508\n",
      "199509\n",
      "199510\n",
      "199511\n",
      "199512\n",
      "199601\n",
      "199602\n",
      "199603\n",
      "199604\n",
      "199605\n",
      "199606\n",
      "199607\n",
      "199608\n",
      "199609\n",
      "199610\n",
      "199611\n",
      "199612\n",
      "199701\n",
      "199702\n",
      "199703\n",
      "199704\n",
      "199705\n",
      "199706\n",
      "199707\n",
      "199708\n",
      "199709\n",
      "199710\n",
      "199711\n",
      "199712\n",
      "199801\n",
      "199802\n",
      "199803\n",
      "199804\n",
      "199805\n",
      "199806\n",
      "199807\n",
      "199808\n",
      "199809\n",
      "199810\n",
      "199811\n",
      "199812\n",
      "199901\n",
      "199902\n",
      "199903\n",
      "199904\n",
      "199905\n",
      "199906\n",
      "199907\n",
      "199908\n",
      "199909\n",
      "199910\n",
      "199911\n",
      "199912\n",
      "200001\n",
      "200002\n",
      "200003\n",
      "200004\n",
      "200005\n",
      "200006\n",
      "200007\n",
      "200008\n",
      "200009\n",
      "200010\n",
      "200011\n",
      "200012\n",
      "200101\n",
      "200102\n",
      "200103\n",
      "200104\n",
      "200105\n",
      "200106\n",
      "200107\n",
      "200108\n",
      "200109\n",
      "200110\n",
      "200111\n",
      "200112\n",
      "200201\n",
      "200202\n",
      "200203\n",
      "200204\n",
      "200205\n",
      "200206\n",
      "200207\n",
      "200208\n",
      "200209\n",
      "200210\n",
      "200211\n",
      "200212\n",
      "200301\n",
      "200302\n",
      "200303\n",
      "200304\n",
      "200305\n",
      "200306\n",
      "200307\n",
      "200308\n",
      "200309\n",
      "200310\n",
      "200311\n",
      "200312\n",
      "200401\n",
      "200402\n",
      "200403\n",
      "200404\n",
      "200405\n",
      "200406\n",
      "200407\n",
      "200408\n",
      "200409\n",
      "200410\n",
      "200411\n",
      "200412\n",
      "200501\n",
      "200502\n",
      "200503\n",
      "200504\n",
      "200505\n",
      "200506\n",
      "200507\n",
      "200508\n",
      "200509\n",
      "200510\n",
      "200511\n",
      "200512\n",
      "200601\n",
      "200602\n",
      "200603\n",
      "200604\n",
      "200605\n",
      "200606\n",
      "200607\n",
      "200608\n",
      "200609\n",
      "200610\n",
      "200611\n",
      "200612\n",
      "200701\n",
      "200702\n",
      "200703\n",
      "200704\n",
      "200705\n",
      "200706\n",
      "200707\n",
      "200708\n",
      "200709\n",
      "200710\n",
      "200711\n",
      "200712\n",
      "200801\n",
      "200802\n",
      "200803\n",
      "200804\n",
      "200805\n",
      "200806\n",
      "200807\n",
      "200808\n",
      "200809\n",
      "200810\n",
      "200811\n",
      "200812\n",
      "200901\n",
      "200902\n",
      "200903\n",
      "200904\n",
      "200905\n",
      "200906\n",
      "200907\n",
      "200908\n",
      "200909\n",
      "200910\n",
      "200911\n",
      "200912\n",
      "201001\n",
      "201002\n",
      "201003\n",
      "201004\n",
      "201005\n",
      "201006\n",
      "201007\n",
      "201008\n",
      "201009\n",
      "201010\n",
      "201011\n",
      "201012\n",
      "201101\n",
      "201102\n",
      "201103\n",
      "201104\n",
      "201105\n",
      "201106\n",
      "201107\n",
      "201108\n",
      "201109\n",
      "201110\n",
      "201111\n",
      "201112\n",
      "201201\n",
      "201202\n",
      "201203\n",
      "201204\n",
      "201205\n",
      "201206\n",
      "201207\n",
      "201208\n",
      "201209\n",
      "201210\n",
      "201211\n",
      "201212\n",
      "201301\n",
      "201302\n",
      "201303\n",
      "201304\n",
      "201305\n",
      "201306\n",
      "201307\n",
      "201308\n",
      "201309\n",
      "201310\n",
      "201311\n",
      "201312\n",
      "201401\n",
      "201402\n",
      "201403\n",
      "201404\n",
      "201405\n",
      "201406\n",
      "201407\n",
      "201408\n",
      "201409\n",
      "201410\n",
      "201411\n",
      "201412\n",
      "201501\n",
      "201502\n",
      "201503\n",
      "201504\n",
      "201505\n",
      "201506\n",
      "201507\n",
      "201508\n",
      "201509\n",
      "201510\n",
      "201511\n",
      "201512\n",
      "201601\n",
      "201602\n",
      "201603\n",
      "201604\n",
      "201605\n",
      "201606\n",
      "201607\n",
      "201608\n",
      "201609\n",
      "201610\n",
      "201611\n",
      "201612\n",
      "201701\n",
      "201702\n",
      "201703\n",
      "201704\n",
      "201705\n",
      "201706\n",
      "201707\n",
      "201708\n",
      "201709\n",
      "201710\n",
      "201711\n",
      "201712\n",
      "201801\n",
      "201802\n",
      "201803\n",
      "201804\n",
      "201805\n",
      "201806\n",
      "201807\n",
      "201808\n",
      "201809\n",
      "201810\n",
      "201811\n",
      "201812\n",
      "201901\n",
      "201902\n",
      "201903\n",
      "201904\n",
      "201905\n",
      "201906\n",
      "201907\n",
      "201908\n",
      "201909\n",
      "201910\n",
      "201911\n",
      "201912\n",
      "202001\n",
      "202002\n",
      "202003\n",
      "202004\n",
      "202005\n",
      "202006\n",
      "202007\n",
      "202008\n",
      "202009\n",
      "202010\n",
      "202011\n",
      "202012\n",
      "202101\n",
      "202102\n",
      "202103\n",
      "202104\n",
      "202105\n",
      "202106\n",
      "202107\n",
      "202108\n",
      "202109\n",
      "202110\n",
      "202111\n",
      "202112\n",
      "202201\n",
      "202202\n",
      "202203\n",
      "202204\n",
      "202205\n",
      "202206\n",
      "202207\n",
      "202208\n",
      "202209\n",
      "202210\n",
      "202211\n",
      "202212\n",
      "202301\n",
      "202302\n",
      "202303\n",
      "202304\n",
      "202305\n",
      "202306\n",
      "202307\n",
      "202308\n",
      "202309\n",
      "202310\n",
      "202311\n",
      "202312\n"
     ]
    }
   ],
   "source": [
    "lons =  pph.lon.values\n",
    "lats = pph.lat.values\n",
    "oldyear = 0\n",
    "\n",
    "for time in displacement_dataset['time'][displacement_dataset['time'] >= '198411010000']:\n",
    "    year = str(time.values)[:6]\n",
    "    if year != oldyear:\n",
    "        displacement_dataset.to_netcdf('data/displacement/displacements2new.nc')\n",
    "        oldyear = year\n",
    "        print(year)\n",
    "    for hazard in hazard_types: \n",
    "        pph_array = pph.sel(time = time)[pph_key_dict[hazard]].data*2.55 # normalize to 8-bit image scale\n",
    "        outlook_array = outlooks.sel(time = time, outlook = outlook_key_dict[hazard])['prob'].data*255 # normalize to 8-bit image scale\n",
    "        x_flow, y_flow, end_lons, end_lats, e_flow, n_flow = flow_day(outlook_array, pph_array, lons, lats)\n",
    "\n",
    "        displacement_dataset['x_flow'].loc[dict(time = time, hazard = hazard)] = x_flow\n",
    "        displacement_dataset['y_flow'].loc[dict(time = time, hazard = hazard)] = y_flow\n",
    "        displacement_dataset['end_lon'].loc[dict(time = time, hazard = hazard)] = end_lons\n",
    "        displacement_dataset['end_lat'].loc[dict(time = time, hazard = hazard)] = end_lats\n",
    "        displacement_dataset['e_flow'].loc[dict(time = time, hazard = hazard)] = e_flow\n",
    "        displacement_dataset['n_flow'].loc[dict(time = time, hazard = hazard)] = n_flow\n",
    "    \n",
    "\n",
    "displacement_dataset.to_netcdf('data/displacement/displacements_final.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add shifts, divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wind\n",
      "Hail\n",
      "Tornado\n",
      "All Hazard\n"
     ]
    }
   ],
   "source": [
    "hazard_types= ['Wind', 'Hail', 'Tornado', 'All Hazard']\n",
    "\n",
    "displacement_dataset = displacement_dataset.assign(e_shift = (('time', 'hazard'), np.full((len(displacement_dataset['time']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(n_shift = (('time', 'hazard'), np.full((len(displacement_dataset['time']), len(hazard_types)), 0.0)))\n",
    "displacement_dataset = displacement_dataset.assign(total_div = (('time', 'hazard'), np.full((len(displacement_dataset['time']), len(hazard_types)), 0.0)))\n",
    "\n",
    "for hazard in hazard_types:\n",
    "\n",
    "    print(hazard)\n",
    "\n",
    "    e_shifts = []\n",
    "    n_shifts = []\n",
    "    total_divs = []\n",
    "\n",
    "    hazard_dataset = displacement_dataset.sel(hazard = hazard)\n",
    "    for date in displacement_dataset['time']:\n",
    "        weights = outlooks.sel(time = date, outlook = outlook_key_dict[hazard])['prob'].data\n",
    "        if weights.max() == 0: # no outlook, so weight at pph\n",
    "            weights = pph.sel(time = date)[pph_key_dict[hazard]].data\n",
    "        if weights.max() == 0:\n",
    "            weights = None\n",
    "        hazard_time_dataset = hazard_dataset.sel(time = date)\n",
    "        e_shift = np.average(hazard_time_dataset['e_flow'], weights = weights)\n",
    "        n_shift = np.average(hazard_time_dataset['n_flow'], weights = weights)\n",
    "        div = np.gradient(hazard_time_dataset['x_flow'])[1] + np.gradient(hazard_time_dataset['y_flow'])[0]\n",
    "        total_div = np.average(div, weights = weights)\n",
    "\n",
    "        displacement_dataset['e_shift'].loc[dict(time = date, hazard = hazard)] = e_shift\n",
    "        displacement_dataset['n_shift'].loc[dict(time = date, hazard = hazard)] = n_shift\n",
    "        displacement_dataset['total_div'].loc[dict(time = date, hazard = hazard)] = total_div\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacement_dataset.to_netcdf('data/displacement/displacements_final.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date = '201305310000'\n",
    "pph_array = pph.sel(time = test_date)['p_perfect_max'].data/100*255 # normalize to 8-bit image scale\n",
    "outlook_array = outlooks.sel(time = test_date, outlook = 'Day 1')['prob'].data*255 # normalize to 8-bit image scale\n",
    "x_flow, y_flow, end_lons, end_lats, e_flow, n_flow = flow_day(outlook_array, pph_array, pph.lon.values, pph.lat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = pph.lon.values\n",
    "lats = pph.lat.values\n",
    "\n",
    "fig=plt.figure(figsize=(9,6), dpi = 1000)\n",
    "ax = plt.axes(projection = cp.crs.LambertConformal())\n",
    "ax.add_feature(cp.feature.LAND,facecolor='grey')\n",
    "ax.add_feature(cp.feature.OCEAN, alpha = 0.5)\n",
    "ax.add_feature(cp.feature.COASTLINE,linewidth=0.5)\n",
    "ax.add_feature(cp.feature.LAKES, alpha = 0.5)\n",
    "ax.add_feature(cp.feature.STATES,linewidth=0.5)\n",
    "ax.contourf(lons, lats, outlook_array/255,\n",
    "                    levels=[.02,.05,.10,.15,.30,.45,.60,1.00], colors=['#008b00','#8b4726','#ffc800', '#ff0000', '#ff00ff', '#912cee', '#104e8b'], transform=cp.crs.PlateCarree())\n",
    "ax.contour(lons, lats, pph_array/255, levels=[.02,.05,.10,.15,.30,.45,.60,1.00], colors = 'black', linestyles = 'dashed', linewidths = .5, transform=cp.crs.PlateCarree())\n",
    "\n",
    "for i in range(lons.shape[0]):\n",
    "    for j in range(lats.shape[1]):\n",
    "        if np.abs(x_flow[i, j]) > .01 and np.abs(y_flow[i, j]) > .01:\n",
    "            ax.add_patch(FancyArrowPatch((lons[i, j], lats[i, j]), (end_lons[i, j], end_lats[i, j]), transform=cp.crs.PlateCarree(), color = 'black', mutation_scale=4, linewidth = .01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = cv.calcOpticalFlowFarneback(outlook_array, pph_array, None, .5, 3, 3, 3, 7, 1.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: handle weights properly when all zero... think about how to do\n",
    "# weighted mean shift\n",
    "x_shift = np.average(flow[:, :, 0], weights = outlook_array)\n",
    "y_shift = np.average(flow[:, :, 1], weights = outlook_array)\n",
    "x_shift*80, y_shift * 80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted mean divergence, range should be approximately (-1, 1)\n",
    "# try basic method with np.gradient. Will then use metpy gradient but need flow vectors to have proper units first\n",
    "\n",
    "div = np.gradient(flow[:, :, 0])[1] + np.gradient(flow[:, :, 1])[0]\n",
    "total_div = np.average(div, weights = outlook_array)\n",
    "total_div\n",
    "\n",
    "\n",
    "curl = np.gradient(flow[:, :, 0])[0] + np.gradient(flow[:, :, 1])[1]\n",
    "total_curl = np.average(curl, weights = outlook_array)\n",
    "\n",
    "total_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(div)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_displacements = xr.open_dataset('data/displacement/displacements.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
